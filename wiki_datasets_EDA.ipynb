{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.max_rows', 1000)  # 최대 1000개 행 출력 허용\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_words(df, dataname,  min_count=10, language='english'):\n",
    "    if dataname == 'sql':\n",
    "        text_col='query'\n",
    "    else: \n",
    "        text_col='question'\n",
    "    stop_words = set(stopwords.words(language))\n",
    "\n",
    "    # 모든 문장을 하나로 합친 뒤 소문자 변환 + 특수문자 제거\n",
    "    text = ' '.join(df[text_col]).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수문자 제거\n",
    "\n",
    "    # 토큰화 후 불용어 제거\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # 단어 개수 세기\n",
    "    word_counts = pd.Series(words).value_counts()\n",
    "    return word_counts[word_counts >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def annotate_question(question):\n",
    "    q_lower = question.lower()\n",
    "    \n",
    "    if re.search(r'\\bhow many\\b', q_lower) or \\\n",
    "       re.search(r'\\b(total|sum|count|average)\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    if re.search(r'\\b(highest|lowest|most|least|fastest|slowest)\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    if re.search(r'\\b(which|what|who)\\b', q_lower):\n",
    "        return 'Lookup'\n",
    "    \n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"wikitablequestions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets['train']\n",
    "val = pd.DataFrame(datasets['validation'])\n",
    "test = pd.DataFrame(datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11321\n",
      "2831\n",
      "4344\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(val))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eunji/.pyenv/versions/3.10.9/envs/tableqa/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"neulab/omnitab-large\")\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "results = {}\n",
    "over_1024 = {}   \n",
    "\n",
    "# 각 데이터셋(train, test, validation)에 대해 처리\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    data = datasets[split]\n",
    "\n",
    "    # 각 테이블의 토큰 개수 계산\n",
    "    token_counts = []\n",
    "    over_1024[split] = []  # split별 리스트 초기화\n",
    "\n",
    "    for sample in data:\n",
    "        table = sample[\"table\"]  # 테이블 데이터 가져오기\n",
    "\n",
    "        # Pandas DataFrame 변환\n",
    "        df_table = pd.DataFrame(table[\"rows\"], columns=table[\"header\"])\n",
    "\n",
    "        # TAPEX는 DataFrame과 질문을 함께 입력받아야 함\n",
    "        tokenized = tokenizer(table=df_table, query=sample[\"question\"], truncation=False)\n",
    "\n",
    "        # input_ids가 리스트인지 확인 후 길이 측정\n",
    "        token_count = len(tokenized[\"input_ids\"]) if isinstance(tokenized[\"input_ids\"], list) else tokenized[\"input_ids\"]\n",
    "        token_counts.append(token_count)\n",
    "\n",
    "        # 1024 초과인 경우 저장\n",
    "        if token_count > 1024:\n",
    "            over_1024[split].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1987, 'test': 607, 'validation': 496}\n"
     ]
    }
   ],
   "source": [
    "print({k: len(v) for k, v in over_1024.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "over_train = random.sample(over_1024['train'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eunji/workspace/kim-internship/Eunji/over_train.json', 'w', encoding='utf-8') as f:\n",
    "   json.dump(over_train, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eunji/workspace/kim-internship/Eunji/over_val.json', 'w', encoding='utf-8') as f:\n",
    "   json.dump(over_1024['validation'], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eunji/workspace/kim-internship/Eunji/over_test.json', 'w', encoding='utf-8') as f:\n",
    "   json.dump(over_1024['test'], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eunji/workspace/kim-internship/Eunji/over_train.json', 'r', encoding='utf-8') as f:\n",
    "    over_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtrain = pd.DataFrame(over_train)\n",
    "overval = pd.DataFrame(over_1024['validation'])\n",
    "overtest = pd.DataFrame(over_1024['test'])\n",
    "#over_query = overtrain['question'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : annotation\n",
      "Lookup         436\n",
      "Aggregation    432\n",
      "Other          132\n",
      "Name: count, dtype: int64\n",
      "validation : annotation\n",
      "Lookup         224\n",
      "Aggregation    214\n",
      "Other           58\n",
      "Name: count, dtype: int64\n",
      "test:annotation\n",
      "Lookup         278\n",
      "Aggregation    244\n",
      "Other           85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 각 질문에 annotation 적용\n",
    "overtrain['annotation'] = overtrain['question'].apply(annotate_question)\n",
    "overval['annotation'] = overval['question'].apply(annotate_question)\n",
    "overtest['annotation'] = overtest['question'].apply(annotate_question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'train : {overtrain[\"annotation\"].value_counts()}')\n",
    "print(f\"validation : {overval['annotation'].value_counts()}\")\n",
    "print(f\"test:{overtest['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "overtrain_others = overtrain[overtrain['annotation'] == \"Other\"]\n",
    "overval_others = overval[overval['annotation']==\"Other\"]\n",
    "overtest_others = overtest[overtest['annotation']==\"Other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "number     19\n",
       "long       15\n",
       "first      12\n",
       "one        10\n",
       "name        8\n",
       "route       7\n",
       "list        6\n",
       "last        6\n",
       "game        6\n",
       "unicode     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(overtest_others, dataname=\"tq\", min_count=2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        9\n",
       "long        8\n",
       "last        7\n",
       "hospital    5\n",
       "number      5\n",
       "first       5\n",
       "state       4\n",
       "saros       4\n",
       "county      4\n",
       "largest     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(overval_others, dataname=\"tq\", min_count=2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      28\n",
       "long      21\n",
       "number    12\n",
       "first     10\n",
       "year       9\n",
       "last       8\n",
       "one        7\n",
       "held       7\n",
       "game       6\n",
       "listed     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(overtrain_others, dataname=\"tq\", min_count=2)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overval_others[overval_others['annotation']==\"Other\"][]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql = load_dataset(\"wikisql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql_val= pd.DataFrame(wikisql['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['phase', 'question', 'table', 'sql'], dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikisql_val.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_query = wikisql_val['question'].tolist()\n",
    "val_header =  wikisql_val['table'].apply(lambda x: x['header']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"None\", \"Max\", \"Min\", \"Count\", \"Sum\", \"Average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label:id for id, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql_val_agg = wikisql_val['sql'].apply(lambda x: x['agg']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_qt = [id2label[x] for x in wikisql_val_agg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.DataFrame({'query': val_query, 'header': val_header, 'agg': wikisql_val_agg, 'agg_label': val_qt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "none_val = val_data[val_data['agg']==0]\n",
    "max_val = val_data[val_data['agg']==1]\n",
    "min_val = val_data[val_data['agg']==2]\n",
    "count_val =  val_data[val_data['agg']==3]\n",
    "sum_val =  val_data[val_data['agg']==4]\n",
    "avg_val =  val_data[val_data['agg']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6017 507 468 779 321 329\n"
     ]
    }
   ],
   "source": [
    "print(len(none_val), len(max_val), len(min_val), len(count_val), len(sum_val), len(avg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_words_for_none(df, text_col='query', min_count=10):\n",
    "    words = ' '.join(df[text_col]).split()\n",
    "    word_counts = pd.Series(words).value_counts()\n",
    "    return word_counts[word_counts >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     6385\n",
       "is      3124\n",
       "of      2985\n",
       "What    2892\n",
       "a       1718\n",
       "was     1489\n",
       "for     1033\n",
       "and     1024\n",
       "has     1001\n",
       "when     934\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words_for_none(none_val)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average    231\n",
       "less        81\n",
       "number      54\n",
       "total       47\n",
       "0           44\n",
       "1           43\n",
       "larger      34\n",
       "smaller     34\n",
       "points      33\n",
       "rank        32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(avg_val, dataname=\"sql\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highest    213\n",
       "number     101\n",
       "less        76\n",
       "larger      47\n",
       "name        45\n",
       "total       42\n",
       "points      42\n",
       "smaller     42\n",
       "team        38\n",
       "year        37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(max_val, dataname=\"sql\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "many       397\n",
       "total      258\n",
       "number     251\n",
       "name        79\n",
       "less        72\n",
       "points      69\n",
       "larger      51\n",
       "smaller     44\n",
       "goals       42\n",
       "0           41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(count_val, dataname=\"sql\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum        94\n",
       "total      84\n",
       "many       71\n",
       "less       64\n",
       "number     40\n",
       "points     33\n",
       "0          32\n",
       "1          32\n",
       "greater    30\n",
       "larger     30\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(sum_val, dataname=\"sql\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average    231\n",
       "less        81\n",
       "number      54\n",
       "total       47\n",
       "0           44\n",
       "1           43\n",
       "larger      34\n",
       "smaller     34\n",
       "points      33\n",
       "rank        32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_frequent_words(avg_val, dataname=\"sql\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tableqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
