{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#pd.set_option('display.max_rows', 1000)  # 최대 1000개 행 출력 허용\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_words(df, dataname, min_count=10, language='english'):\n",
    "    if dataname == 'sql':\n",
    "        text_col='query'\n",
    "    else: \n",
    "        text_col='question'\n",
    "    stop_words = set(stopwords.words(language))\n",
    "\n",
    "    # 모든 문장을 하나로 합친 뒤 소문자 변환 + 특수문자 제거\n",
    "    text = ' '.join(df[text_col]).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 특수문자 제거\n",
    "\n",
    "    # 토큰화 후 불용어 제거\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # 단어 개수 세기\n",
    "    word_counts = pd.Series(words).value_counts()\n",
    "    return word_counts[word_counts >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def annotate_question(question):\n",
    "    q_lower = question.lower()\n",
    "\n",
    "    # 일반적인 'lookup' 조건 \n",
    "    if re.search(r'\\b(which|what|who|name)\\b', q_lower):\n",
    "        return 'Lookup'\n",
    "    \n",
    "    # WikiTQ 데이터셋에서 추가된\n",
    "    # 'where'과 'first'가 동시에 있을 때\n",
    "    if 'when' in q_lower and 'first' in q_lower:\n",
    "        return 'Lookup'\n",
    "    \n",
    "    if re.search(r'\\b(where)\\b', q_lower):\n",
    "        return 'Lookup'\n",
    "\n",
    "    # 일반적인 'Aggregation' 조건 \n",
    "    if re.search(r'\\bhow many\\b', q_lower) or \\\n",
    "       re.search(r'\\b(total|sum|count|average)\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    # WikiTQ 데이터셋에서 추가된 Aggregation 조건 \n",
    "    if re.search(r'\\b(highest|lowest|most|least|fastest|slowest|largest|fewest)\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    if re.search(r'\\bnumber of\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    if re.search(r'\\b(is|were|was|does|did)\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    if re.search(r'\\bmore or less\\b', q_lower):\n",
    "        return 'Aggregation'\n",
    "    \n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "datasets = load_dataset(\"wikitablequestions\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(datasets['train'])\n",
    "val = pd.DataFrame(datasets['validation'])\n",
    "test = pd.DataFrame(datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11321\n",
      "4344\n",
      "2831\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m df_table = pd.DataFrame(table[\u001b[33m\"\u001b[39m\u001b[33mrows\u001b[39m\u001b[33m\"\u001b[39m], columns=table[\u001b[33m\"\u001b[39m\u001b[33mheader\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# TAPEX(OmniTab)는 DataFrame과 질문을 함께 입력받아야 함\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m tokenized = \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# input_ids가 리스트인지 확인 후 길이 측정\u001b[39;00m\n\u001b[32m     27\u001b[39m token_count = \u001b[38;5;28mlen\u001b[39m(tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m], \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m tokenized[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\models\\deprecated\\tapex\\tokenization_tapex.py:531\u001b[39m, in \u001b[36mTapexTokenizer.__call__\u001b[39m\u001b[34m(self, table, query, answer, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    518\u001b[39m \u001b[33;03mMain method to tokenize and prepare for the model one or several table-sequence pair(s).\u001b[39;00m\n\u001b[32m    519\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    527\u001b[39m \u001b[33;03m        Optionally, the corresponding answer to the questions as supervision.\u001b[39;00m\n\u001b[32m    528\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_call_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    547\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.target_call_func(\n\u001b[32m    553\u001b[39m         answer=answer,\n\u001b[32m    554\u001b[39m         add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m         **kwargs,\n\u001b[32m    569\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\models\\deprecated\\tapex\\tokenization_tapex.py:640\u001b[39m, in \u001b[36mTapexTokenizer.source_call_func\u001b[39m\u001b[34m(self, table, query, answer, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.batch_encode_plus(\n\u001b[32m    621\u001b[39m         table=table,\n\u001b[32m    622\u001b[39m         query=query,\n\u001b[32m   (...)\u001b[39m\u001b[32m    637\u001b[39m         **kwargs,\n\u001b[32m    638\u001b[39m     )\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m640\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\models\\deprecated\\tapex\\tokenization_tapex.py:909\u001b[39m, in \u001b[36mTapexTokenizer.encode_plus\u001b[39m\u001b[34m(self, table, query, answer, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    879\u001b[39m \u001b[38;5;129m@add_end_docstrings\u001b[39m(ENCODE_KWARGS_DOCSTRING, TAPEX_ENCODE_PLUS_ADDITIONAL_KWARGS_DOCSTRING)\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_plus\u001b[39m(\n\u001b[32m    881\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    898\u001b[39m ) -> BatchEncoding:\n\u001b[32m    899\u001b[39m     \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[32m    900\u001b[39m     padding_strategy, truncation_strategy, max_length, kwargs = \u001b[38;5;28mself\u001b[39m._get_padding_truncation_strategies(\n\u001b[32m    901\u001b[39m         padding=padding,\n\u001b[32m    902\u001b[39m         truncation=truncation,\n\u001b[32m   (...)\u001b[39m\u001b[32m    906\u001b[39m         **kwargs,\n\u001b[32m    907\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m        \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m=\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    913\u001b[39m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    914\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\models\\deprecated\\tapex\\tokenization_tapex.py:966\u001b[39m, in \u001b[36mTapexTokenizer._encode_plus\u001b[39m\u001b[34m(self, table, query, answer, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[39m\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.do_lower_case:\n\u001b[32m    964\u001b[39m     text = text.lower()\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m tokens = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.prepare_for_model(\n\u001b[32m    969\u001b[39m     ids=\u001b[38;5;28mself\u001b[39m.convert_tokens_to_ids(tokens),\n\u001b[32m    970\u001b[39m     add_special_tokens=add_special_tokens,\n\u001b[32m   (...)\u001b[39m\u001b[32m    983\u001b[39m     verbose=verbose,\n\u001b[32m    984\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\tokenization_utils.py:697\u001b[39m, in \u001b[36mPreTrainedTokenizer.tokenize\u001b[39m\u001b[34m(self, text, **kwargs)\u001b[39m\n\u001b[32m    695\u001b[39m         tokenized_text.append(token)\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m697\u001b[39m         tokenized_text.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    698\u001b[39m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\transformers\\models\\deprecated\\tapex\\tokenization_tapex.py:445\u001b[39m, in \u001b[36mTapexTokenizer._tokenize\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Tokenize a string.\"\"\"\u001b[39;00m\n\u001b[32m    444\u001b[39m bpe_tokens = []\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    446\u001b[39m     token = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    447\u001b[39m         \u001b[38;5;28mself\u001b[39m.byte_encoder[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m token.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    448\u001b[39m     )  \u001b[38;5;66;03m# Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\u001b[39;00m\n\u001b[32m    449\u001b[39m     bpe_tokens.extend(bpe_token \u001b[38;5;28;01mfor\u001b[39;00m bpe_token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bpe(token).split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\B6313\\miniconda3\\envs\\wiki_cls\\Lib\\site-packages\\regex\\regex.py:338\u001b[39m, in \u001b[36mfindall\u001b[39m\u001b[34m(pattern, string, flags, pos, endpos, overlapped, concurrent, timeout, ignore_unused, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a list of all matches in the string. The matches may be overlapped\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mif overlapped is True. If one or more groups are present in the pattern,\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[33;03mreturn a list of groups; this will be a list of tuples if the pattern has\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[33;03mmore than one group. Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[32m    337\u001b[39m pat = _compile(pattern, flags, ignore_unused, kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"neulab/omnitab-large\")\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "results = {}\n",
    "over_1024 = {}   \n",
    "under_1024 = {}\n",
    "\n",
    "# 각 데이터셋(train, test, validation)에 대해 처리\n",
    "for split in [\"train\", \"test\", \"validation\"]:\n",
    "    data = datasets[split]\n",
    "\n",
    "    # 각 테이블의 토큰 개수 계산\n",
    "    token_counts = []\n",
    "    under_1024[split] = []\n",
    "    over_1024[split] = []  # split별 리스트 초기화\n",
    "\n",
    "    for sample in data:\n",
    "        table = sample[\"table\"]  # 테이블 데이터 가져오기\n",
    "\n",
    "        # Pandas DataFrame 변환\n",
    "        df_table = pd.DataFrame(table[\"rows\"], columns=table[\"header\"])\n",
    "\n",
    "        # TAPEX(OmniTab)는 DataFrame과 질문을 함께 입력받아야 함\n",
    "        tokenized = tokenizer(table=df_table, query=sample[\"question\"], truncation=False)\n",
    "\n",
    "        # input_ids가 리스트인지 확인 후 길이 측정\n",
    "        token_count = len(tokenized[\"input_ids\"]) if isinstance(tokenized[\"input_ids\"], list) else tokenized[\"input_ids\"]\n",
    "        token_counts.append(token_count)\n",
    "\n",
    "        # 1024 초과인 경우 저장\n",
    "        if token_count > 1024:\n",
    "            over_1024[split].append(sample)\n",
    "        else: \n",
    "            under_1024[split].append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1987, 'test': 607, 'validation': 496}\n",
      "{'train': 9334, 'test': 3737, 'validation': 2335}\n"
     ]
    }
   ],
   "source": [
    "print({k: len(v) for k, v in over_1024.items()})\n",
    "print({k: len(v) for k, v in under_1024.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "over_train = random.sample(over_1024['train'], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'C:/Users/B6313/BERT-AGG-MODEL/wikiTQ_json'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    # over_1024 저장\n",
    "    over_path = os.path.join(output_dir, f'over_{split}.json')\n",
    "    with open(over_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(over_1024[split], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # under_1024 저장\n",
    "    under_path = os.path.join(output_dir, f'under_{split}.json')\n",
    "    with open(under_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(under_1024[split], f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_1024 ={}\n",
    "under_1024 = {}\n",
    "\n",
    "over_1024_df = {}\n",
    "under_1024_df = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    # over_1024 불러오기\n",
    "    over_path = os.path.join(output_dir, f'over_{split}.json')\n",
    "    with open(over_path, 'r', encoding='utf-8') as f:\n",
    "        over_1024[split] = json.load(f)\n",
    "        over_1024_df[split] = pd.DataFrame(over_1024[split])\n",
    "    \n",
    "    # under_1024 불러오기\n",
    "    under_path = os.path.join(output_dir, f'under_{split}.json')\n",
    "    with open(under_path, 'r', encoding='utf-8') as f:\n",
    "        under_1024[split] = json.load(f)\n",
    "        under_1024_df[split] = pd.DataFrame(under_1024[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[under_1024] train: \n",
      "annotation\n",
      "Lookup         5917\n",
      "Aggregation    3235\n",
      "Other           182\n",
      "Name: count, dtype: int64\n",
      "[under_1024] validation: \n",
      "annotation\n",
      "Lookup         1454\n",
      "Aggregation     813\n",
      "Other            68\n",
      "Name: count, dtype: int64\n",
      "[under_1024] test: \n",
      "annotation\n",
      "Lookup         2328\n",
      "Aggregation    1319\n",
      "Other            90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    under_1024_df[split]['annotation'] = under_1024_df[split]['question'].apply(annotate_question)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[under_1024] {split}: \\n{under_1024_df[split]['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[over_1024_df] train: \n",
      "annotation\n",
      "Lookup         1265\n",
      "Aggregation     676\n",
      "Other            46\n",
      "Name: count, dtype: int64\n",
      "[over_1024_df] validation: \n",
      "annotation\n",
      "Lookup         336\n",
      "Aggregation    156\n",
      "Other            4\n",
      "Name: count, dtype: int64\n",
      "[over_1024_df] test: \n",
      "annotation\n",
      "Lookup         363\n",
      "Aggregation    226\n",
      "Other           18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    over_1024_df[split]['annotation'] = over_1024_df[split]['question'].apply(annotate_question)\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[over_1024_df] {split}: \\n{over_1024_df[split]['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>question</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'header': ['Rank', 'Cyclist', 'Team', 'Time',...</td>\n",
       "      <td>which country had the most cyclists finish wit...</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'header': ['Description Losses', '1939/40', '...</td>\n",
       "      <td>how many people were murdered in 1940/41?</td>\n",
       "      <td>Aggregation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'header': ['Year', 'Division', 'League', 'Reg...</td>\n",
       "      <td>how long did it take for the new york american...</td>\n",
       "      <td>Aggregation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'header': ['Series #', 'Season #', 'Title', '...</td>\n",
       "      <td>alfie's birthday party aired on january 19. wh...</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'header': ['Date', 'Competition', 'Location',...</td>\n",
       "      <td>what is the number of 1st place finishes acros...</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'header': ['Year', 'Competition', 'Venue', 'P...</td>\n",
       "      <td>in which competition did hopley finish fist?</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'header': ['Year', 'Film', 'Role', 'Language'...</td>\n",
       "      <td>what is the total number of films with the lan...</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'header': ['Game', 'Day', 'Date', 'Kickoff', ...</td>\n",
       "      <td>what was the number of people attending the to...</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'header': ['Year', 'Kit Manufacturer', 'Shirt...</td>\n",
       "      <td>what time period had no shirt sponsor?</td>\n",
       "      <td>Lookup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'header': ['Year', 'Competition', 'Venue', 'P...</td>\n",
       "      <td>when was his first 1st place record?</td>\n",
       "      <td>Aggregation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               table  \\\n",
       "0  {'header': ['Rank', 'Cyclist', 'Team', 'Time',...   \n",
       "1  {'header': ['Description Losses', '1939/40', '...   \n",
       "2  {'header': ['Year', 'Division', 'League', 'Reg...   \n",
       "3  {'header': ['Series #', 'Season #', 'Title', '...   \n",
       "4  {'header': ['Date', 'Competition', 'Location',...   \n",
       "5  {'header': ['Year', 'Competition', 'Venue', 'P...   \n",
       "6  {'header': ['Year', 'Film', 'Role', 'Language'...   \n",
       "7  {'header': ['Game', 'Day', 'Date', 'Kickoff', ...   \n",
       "8  {'header': ['Year', 'Kit Manufacturer', 'Shirt...   \n",
       "9  {'header': ['Year', 'Competition', 'Venue', 'P...   \n",
       "\n",
       "                                            question   annotation  \n",
       "0  which country had the most cyclists finish wit...       Lookup  \n",
       "1          how many people were murdered in 1940/41?  Aggregation  \n",
       "2  how long did it take for the new york american...  Aggregation  \n",
       "3  alfie's birthday party aired on january 19. wh...       Lookup  \n",
       "4  what is the number of 1st place finishes acros...       Lookup  \n",
       "5       in which competition did hopley finish fist?       Lookup  \n",
       "6  what is the total number of films with the lan...       Lookup  \n",
       "7  what was the number of people attending the to...       Lookup  \n",
       "8             what time period had no shirt sponsor?       Lookup  \n",
       "9               when was his first 1st place record?  Aggregation  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_1024_df['test'][['table', 'question', 'annotation']][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under_1024_df['train'][under_1024_df['train']['annotation'].str.contains('Other', case=False, na=False)][10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[filtered_under_1024_df] train: \n",
      "annotation\n",
      "Lookup         5917\n",
      "Aggregation    3235\n",
      "Name: count, dtype: int64\n",
      "[filtered_under_1024_df] validation: \n",
      "annotation\n",
      "Lookup         1454\n",
      "Aggregation     813\n",
      "Name: count, dtype: int64\n",
      "[filtered_under_1024_df] test: \n",
      "annotation\n",
      "Lookup         2328\n",
      "Aggregation    1319\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_under_1024_df = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    df = under_1024_df[split]\n",
    "    filtered_under_1024_df[split] = df[df['annotation'].isin(['Lookup', 'Aggregation'])]\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[filtered_under_1024_df] {split}: \\n{filtered_under_1024_df[split]['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[filtered_over_1024_df] train: \n",
      "annotation\n",
      "Lookup         1265\n",
      "Aggregation     676\n",
      "Name: count, dtype: int64\n",
      "[filtered_over_1024_df] validation: \n",
      "annotation\n",
      "Lookup         336\n",
      "Aggregation    156\n",
      "Name: count, dtype: int64\n",
      "[filtered_over_1024_df] test: \n",
      "annotation\n",
      "Lookup         363\n",
      "Aggregation    226\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_over_1024_df = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    df1 = over_1024_df[split]\n",
    "    filtered_over_1024_df[split] = df1[df1['annotation'].isin(['Lookup', 'Aggregation'])]\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[filtered_over_1024_df] {split}: \\n{filtered_over_1024_df[split]['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 라벨 None을 'annotation'열에서 Lookup으로 바꾸기\n",
    "2. Lookup을 제외한 나머지 라벨은 'annotation'열에서 Aggregation으로 바꾸기\n",
    "3. 개수 차이나는지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql = load_dataset(\"wikisql\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 15878, 'validation': 8421, 'train': 56355}\n"
     ]
    }
   ],
   "source": [
    "print({k: len(v) for k, v in wikisql.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql_df = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    wikisql_df[split] = pd.DataFrame(wikisql[split])\n",
    "    wikisql_df[split]['annotation'] = wikisql_df[split]['sql'].apply(\n",
    "        lambda x: 'Lookup' if x['agg'] == 0 else 'Aggregation'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[wikisql_df] train: \n",
      "annotation\n",
      "Lookup         40606\n",
      "Aggregation    15749\n",
      "Name: count, dtype: int64\n",
      "[wikisql_df] validation: \n",
      "annotation\n",
      "Lookup         6017\n",
      "Aggregation    2404\n",
      "Name: count, dtype: int64\n",
      "[wikisql_df] test: \n",
      "annotation\n",
      "Lookup         11324\n",
      "Aggregation     4554\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[wikisql_df] {split}: \\n{wikisql_df[split]['annotation'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 개수 차이가 나므로 비율 정해서 언더샘플링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]\n",
      "annotation\n",
      "Lookup         0.720539\n",
      "Aggregation    0.279461\n",
      "Name: count, dtype: float64\n",
      "\n",
      "[validation]\n",
      "annotation\n",
      "Lookup         0.714523\n",
      "Aggregation    0.285477\n",
      "Name: count, dtype: float64\n",
      "\n",
      "[test]\n",
      "annotation\n",
      "Lookup         0.713188\n",
      "Aggregation    0.286812\n",
      "Name: count, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def agg_ratio(df):\n",
    "    return df['annotation'].value_counts() / df['annotation'].value_counts().sum()\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[{split}]\")\n",
    "    print(agg_ratio(wikisql_df[split]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(df, target_col='annotation', target_class='Lookup', target_ratio=0.35, random_state=7):\n",
    "    # 클래스별로 분리\n",
    "    majority = df[df[target_col] == target_class]\n",
    "    others = df[df[target_col] != target_class]\n",
    "\n",
    "    # 목표 비율에 맞게 클래스 'Lookup'에서 일부만 샘플링\n",
    "    target_n = int(len(df) * target_ratio)\n",
    "    #print(f'traget_n :{target_n}')\n",
    "    sampled_majority = majority.sample(n=target_n, random_state=random_state)\n",
    "\n",
    "    # 합치기\n",
    "    balanced_df = pd.concat([sampled_majority, others], axis=0).sample(frac=1, random_state=random_state).reset_index(drop=True) # frac=1 → 전체 행을 다 섞음 (shuffle)\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikisql_balanced_df = {}\n",
    "\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    wikisql_balanced_df[split] = undersample(wikisql_df[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train]\n",
      "annotation\n",
      "Lookup         19724\n",
      "Aggregation    15749\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "[validation]\n",
      "annotation\n",
      "Lookup         2947\n",
      "Aggregation    2404\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "[test]\n",
      "annotation\n",
      "Lookup         5557\n",
      "Aggregation    4554\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'validation', 'test']:\n",
    "    print(f\"[{split}]\")\n",
    "    print(wikisql_balanced_df[split]['annotation'].value_counts().round(2), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. wikisql 데이터와 wikiTableQuestion 데이터 join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'question', 'answers', 'table', 'annotation'], dtype='object')\n",
      "Index(['phase', 'question', 'table', 'sql', 'annotation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(filtered_under_1024_df['train'].columns)\n",
    "print(wikisql_balanced_df['train'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = {}\n",
    "\n",
    "for split in ['train', 'validation']:\n",
    "    df1 = filtered_under_1024_df[split][['question', 'table', 'annotation']].copy()\n",
    "    df2 = wikisql_balanced_df[split][['question', 'table', 'annotation']].copy()\n",
    "    df3 = filtered_over_1024_df[split][['question', 'table', 'annotation']].copy()\n",
    "\n",
    "    # 필요하다면 source 구분\n",
    "    df1['source'] = 'wikitq'\n",
    "    df2['source'] = 'wikisql'\n",
    "    df3['source'] = 'wikitq'\n",
    "\n",
    "    for df in [df1, df2, df3]:\n",
    "        df['annotation_num'] = df['annotation'].map({'Lookup':0, 'Aggregation':1})\n",
    "\n",
    "    combined[split] = pd.concat([df1, df2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation']:\n",
    "    combined[split]['header'] = combined[split]['table'].apply(lambda x: x['header'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'validation']:\n",
    "    file_path = os.path.join(output_dir, f'combined_{split}.json')\n",
    "    combined[split].to_json(file_path, force_ascii=False, orient='records', indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = {}\n",
    "\n",
    "# for split in ['train', 'validation', 'test']:\n",
    "#     file_path = os.path.join(output_dir, f'combined_{split}.json')\n",
    "#     with open(file_path, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "#         combined[split] = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "table",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "annotation",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "annotation_num",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "header",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dec628d1-aee0-4d52-bd12-b36459cc3103",
       "rows": [
        [
         "0",
         "which team won previous to crettyard?",
         "{'header': ['Team', 'County', 'Wins', 'Years won'], 'rows': [['Greystones', 'Wicklow', '1', '2011'], ['Ballymore Eustace', 'Kildare', '1', '2010'], ['Maynooth', 'Kildare', '1', '2009'], ['Ballyroan Abbey', 'Laois', '1', '2008'], ['Fingal Ravens', 'Dublin', '1', '2007'], ['Confey', 'Kildare', '1', '2006'], ['Crettyard', 'Laois', '1', '2005'], ['Wolfe Tones', 'Meath', '1', '2004'], ['Dundalk Gaels', 'Louth', '1', '2003']], 'name': 'csv/204-csv/772.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Team', 'County', 'Wins', 'Years won']"
        ],
        [
         "1",
         "how many more passengers flew to los angeles than to saskatoon from manzanillo airport in 2013?",
         "{'header': ['Rank', 'City', 'Passengers', 'Ranking', 'Airline'], 'rows': [['1', 'United States, Los Angeles', '14,749', '', 'Alaska Airlines'], ['2', 'United States, Houston', '5,465', '', 'United Express'], ['3', 'Canada, Calgary', '3,761', '', 'Air Transat, WestJet'], ['4', 'Canada, Saskatoon', '2,282', '4', ''], ['5', 'Canada, Vancouver', '2,103', '', 'Air Transat'], ['6', 'United States, Phoenix', '1,829', '1', 'US Airways'], ['7', 'Canada, Toronto', '1,202', '1', 'Air Transat, CanJet'], ['8', 'Canada, Edmonton', '110', '', ''], ['9', 'United States, Oakland', '107', '', '']], 'name': 'csv/203-csv/515.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Rank', 'City', 'Passengers', 'Ranking', 'Airline']"
        ],
        [
         "2",
         "after winning on four credits with a full house, what is your payout?",
         "{'header': ['Hand', '1 credit', '2 credits', '3 credits', '4 credits', '5 credits'], 'rows': [['Royal flush', '250', '500', '750', '1000', '4000*'], ['Straight flush', '60', '120', '180', '240', '400'], ['Four aces', '400', '800', '1200', '1600', '2000'], ['Four of a kind, 2-4', '100', '200', '300', '400', '500'], ['Four of a kind, 5-K', '50', '100', '150', '200', '250'], ['Full house', '8', '16', '24', '32', '40'], ['Flush', '5', '10', '15', '20', '25'], ['Straight', '4', '8', '12', '16', '20'], ['Three of a kind', '3', '6', '9', '12', '15'], ['Two pair', '1', '2', '3', '4', '5'], ['Jacks or better', '1', '2', '3', '4', '5'], ['Theoretical return', '98.68%', '98.68%', '98.68%', '98.68%', '99.92%*']], 'name': 'csv/203-csv/564.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Hand', '1 credit', '2 credits', '3 credits', '4 credits', '5 credits']"
        ],
        [
         "3",
         "which players played the same position as ardo kreek?",
         "{'header': ['No.', 'Player', 'Birth Date', 'Weight', 'Height', 'Position', 'Current Club'], 'rows': [['4', 'Ardo Kreek', 'August 7, 1986 (age\\xa027)', '96', '203', 'Middle blocker', 'Paris Volley'], ['5', 'Kert Toobal', 'June 3, 1979 (age\\xa035)', '78', '189', 'Setter', 'Sivas 4 Eylül'], ['6', 'Martti Juhkami', 'June 6, 1988 (age\\xa026)', '96', '196', 'Spiker', 'TV Bühl'], ['7', 'Argo Meresaar', 'January 13, 1980 (age\\xa034)', '107', '206', 'Opposite', 'Bigbank Tartu'], ['8', 'Kusti Nõlvak', 'November 6, 1991 (age\\xa022)', '81', '186', 'Setter', 'TTÜ VK'], ['9', 'Robert Täht', 'August 15, 1993 (age\\xa020)', '80', '190', 'Spiker', 'Bigbank Tartu'], ['11', 'Oliver Venno', 'May 23, 1990 (age\\xa024)', '105', '210', 'Opposite', 'Rennes Volley 35'], ['14', 'Rait Rikberg', 'August 30, 1982 (age\\xa031)', '80', '174', 'Libero', 'Bigbank Tartu'], ['16', 'Edgar Järvekülg', 'June 12, 1988 (age\\xa026)', '77', '186', 'Libero', 'Pärnu VK'], ['17', 'Siim Ennemuist', 'December 5, 1989 (age\\xa024)', '89', '196', 'Middle blocker', 'TTÜ VK'], ['18', 'Jaanus Nõmmsalu', 'January 19, 1981 (age\\xa033)', '94', '200', 'Spiker', 'TTÜ VK'], ['19', 'Andri Aganits', 'September 7, 1993 (age\\xa020)', '99', '207', 'Middle Blocker', 'TV Bühl']], 'name': 'csv/203-csv/116.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['No.', 'Player', 'Birth Date', 'Weight', 'Height', 'Position', 'Current Club']"
        ],
        [
         "4",
         "what was the venue when he placed first?",
         "{'header': ['Year', 'Competition', 'Venue', 'Position', 'Notes'], 'rows': [['1996', 'World Junior Championships', 'Sydney, Australia', '15th (q)', '7.43 m'], ['1996', 'Asian Junior Championships', 'New Delhi, India', '1st', '7.68 m'], ['1999', 'World Championships', 'Seville, Spain', '6th', '8.01 m'], ['2001', 'East Asian Games', 'Osaka, Japan', '3rd', '7.77 m'], ['2002', 'Asian Championships', 'Colombo, Sri Lanka', '3rd', '7.91 m (w)'], ['2002', 'Asian Games', 'Busan, South Korea', '4th', '7.75 m'], ['2003', 'Universiade', 'Daegu, South Korea', '7th', '7.78 m']], 'name': 'csv/204-csv/706.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Year', 'Competition', 'Venue', 'Position', 'Notes']"
        ],
        [
         "5",
         "who ranked right after turkey?",
         "{'header': ['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total'], 'rows': [['1', 'Russia', '6', '3', '7', '16'], ['2', 'United States', '5', '0', '4', '9'], ['3', 'Japan', '3', '4', '1', '8'], ['4', 'France', '3', '1', '1', '5'], ['5', 'Ukraine', '2', '0', '2', '4'], ['6', 'Turkey', '2', '0', '1', '3'], ['7', 'Sweden', '2', '0', '0', '2'], ['8', 'Iran', '1', '2', '1', '4'], ['9', 'Armenia', '1', '1', '2', '4'], ['10', 'China', '1', '1', '1', '3'], ['11', 'Austria', '1', '0', '0', '1'], ['11', 'Bulgaria', '1', '0', '0', '1'], ['11', 'South Korea', '1', '0', '0', '1'], ['14', 'Germany', '0', '3', '4', '7'], ['15', 'Kazakhstan', '0', '3', '0', '3'], ['16', 'Cuba', '0', '2', '3', '5'], ['17', 'Norway', '0', '2', '0', '2'], ['18', 'Venezuela', '0', '1', '1', '2'], ['19', 'Canada', '0', '1', '0', '1'], ['19', 'Hungary', '0', '1', '0', '1'], ['19', 'Israel', '0', '1', '0', '1'], ['19', 'Moldova', '0', '1', '0', '1'], ['19', 'Poland', '0', '1', '0', '1'], ['19', 'Romania', '0', '1', '0', '1'], ['25', 'Uzbekistan', '0', '0', '1', '1'], ['Total', 'Total', '29', '29', '29', '87']], 'name': 'csv/203-csv/812.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total']"
        ],
        [
         "6",
         "what is the total population in dzhebariki-khaya?",
         "{'header': ['Urban settlements', 'Population', 'Male', 'Female', 'Inhabited localities in jurisdiction'], 'rows': [['Dzhebariki-Khaya\\\\n(Джебарики-Хая)', '1694', '844 (49.8%)', '850 (50.2%)', 'Urban-type settlement of Dzhebariki-Khaya'], ['Khandyga\\\\n(Хандыга)', '6638', '3326 (49.8%)', '3312 (50.2%)', 'Urban-type settlement of Khandyga (administrative centre of the district)'], ['Rural settlements', 'Population', 'Male', 'Female', 'Rural localities in jurisdiction*'], ['Bayagantaysky Nasleg\\\\n(Баягантайский наслег)', '1823', '884 (48.5%)', '939 (51.5%)', 'selo of Krest-Khaldzhan\\\\nselo of Ary-Tolon\\\\nselo of Udarnik'], ['Megino-Aldansky Nasleg\\\\n(Мегино-Алданский наслег)', '1020', '490 (48.0%)', '530 (52.0%)', 'selo of Megino-Aldan'], ['Okhot-Perevozovsky Nasleg\\\\n(Охот-Перевозовский наслег)', '142', '70 (49.3%)', '72 (50.7%)', 'selo of Okhotsky-Perevoz'], ['Sasylsky Nasleg\\\\n(Сасыльский наслег)', '555', '275 (49.5%)', '280 (50.5%)', 'selo of Keskil'], ['Teploklyuchevsky Nasleg\\\\n(Теплоключевский наслег)', '887', '447 (50.4%)', '440 (49.6%)', 'selo of Teply Klyuch\\\\nselo of Aeroport\\\\nselo of Razbilka'], ['Tomponsky National Nasleg\\\\n( Томпонский национальный наслег)', '915', '458 (50.1%)', '457 (49.9%)', 'selo of Topolinoye'], ['Ynginsky Nasleg\\\\n(Ынгинский наслег)', '425', '217 (51.1%)', '208 (48.9%)', 'selo of Novy\\\\nselo of Saydy']], 'name': 'csv/204-csv/6.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Urban settlements', 'Population', 'Male', 'Female', 'Inhabited localities in jurisdiction']"
        ],
        [
         "7",
         "who was the top ranked competitor in this race?",
         "{'header': ['Rank', 'Cyclist', 'Team', 'Laps\\\\ndown', 'Notes'], 'rows': [['1', 'Iryna Shpylova', 'Ukraine', '', 'Q'], ['2', 'Jessie Daams', 'Belgium', '', 'Q'], ['3', 'Eunmi Park', 'South Korea', '-1', 'Q'], ['4', 'Evgeniya Romanyuta', 'Russia', '-1', 'Q'], ['5', 'Andrea Wolfer', 'Switzerland', '-1', 'Q'], ['6', 'Giorgia Bronzini', 'Italy', '-1', 'Q'], ['7', 'Leire Olaberria Dorronsoro', 'Spain', '-1', 'Q'], ['8', 'Joanne Kiesanowski', 'New Zealand', '-1', 'Q'], ['9', 'Dulce Pliego', 'Mexico', '-1', 'Q'], ['10', 'Jessie Maclean', 'Verducci Breakaway Racing', '-1', 'Q'], ['11', 'Lisa Brennauer', 'Germany', '-1', 'Q'], ['12', 'Ashlee Ankudinoff', 'Australia', '-1', 'Q'], ['13', 'Wan Yiu Jamie Wong', 'Hong Kong', '-1', ''], ['14', 'Lauren Franges', 'United States', '-1', ''], ['15', 'Skye Lee Armstrong', 'Rodin', '-1', ''], ['16', 'Rosy Mccall', 'GIS', '-1', ''], ['17', 'Fatehah Mustapa', 'Malaysia', '-1', ''], ['18', 'Yekatsiryna Barazna', 'Belarus', '-1', '']], 'name': 'csv/204-csv/552.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Cyclist', 'Team', 'Laps\\\\ndown', 'Notes']"
        ],
        [
         "8",
         "what was the number of silver medals won by ukraine?",
         "{'header': ['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total'], 'rows': [['1', 'Great Britain\\xa0(GBR)', '2', '1', '2', '5'], ['2', 'Brazil\\xa0(BRA)', '2', '0', '0', '2'], ['3', 'Spain\\xa0(ESP)', '1', '2', '0', '3'], ['4', 'Austria\\xa0(AUT)', '1', '1', '0', '2'], ['4', 'Greece\\xa0(GRE)', '1', '1', '0', '2'], ['4', 'United States\\xa0(USA)', '1', '1', '0', '2'], ['7', 'France\\xa0(FRA)', '1', '0', '1', '2'], ['7', 'Israel\\xa0(ISR)', '1', '0', '0', '1'], ['7', 'Norway\\xa0(NOR)', '1', '0', '0', '1'], ['10', 'Ukraine\\xa0(UKR)', '0', '2', '0', '2'], ['11', 'China\\xa0(CHN)', '0', '1', '0', '1'], ['11', 'Czech Republic\\xa0(CZE)', '0', '1', '0', '1'], ['11', 'Canada\\xa0(CAN)', '0', '1', '0', '1'], ['14', 'Denmark\\xa0(DEN)', '0', '0', '2', '2'], ['15', 'Argentina\\xa0(ARG)', '0', '0', '1', '1'], ['15', 'Italy\\xa0(ITA)', '0', '0', '1', '1'], ['15', 'Japan\\xa0(JPN)', '0', '0', '1', '1'], ['15', 'Poland\\xa0(POL)', '0', '0', '1', '1'], ['15', 'Slovenia\\xa0(SLO)', '0', '0', '1', '1'], ['15', 'Sweden\\xa0(SWE)', '0', '0', '1', '1'], ['Total', '', '11', '11', '11', '33']], 'name': 'csv/203-csv/175.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total']"
        ],
        [
         "9",
         "what is the total number of pylons listed?",
         "{'header': ['Name', 'Year built', 'Country', 'Town', 'Height', 'Remarks'], 'rows': [['Glacial Aerial Tramway Kaprun III', '1966', 'Austria', 'Kaprun', '113.6 m', 'The tallest pylon is on the third section'], ['Mississippi Aerial River Transit', '1984', 'USA', 'New Orleans', '109 m', 'The tallest pylon on a gondola lift; on 87 m pile foundations; demolished 1994'], ['Torre Jaume I', '1931', 'Spain', 'Barcelona', '107 m', 'Intermediate stop of the harbour aerial tramway, also observation tower'], ['Gant Hohtaelli aerial tramway', '', 'Switzerland', 'Zermatt', '94 m', 'One pylon'], ['London Emirates Air Line', 'Early 2012', 'UK', 'London', '88 m', 'North Main Tower. River Thames aerial crossing between Greenwich Peninsular and Royal Docks'], ['Singapore cable car', '1972', 'Singapore', 'Singapore', '88 m', 'Pylon I'], ['Eibsee Aerial Tramway', '1962', 'Germany', 'Garmisch-Partenkirchen', '85 m', 'Pylon II'], ['Nizhny Novgorod Volga Aerial Tramway, Tower 4 & 5', '2012', 'Russia', 'Nizhny Novgorod', '82 m', ''], ['Mittersill goods aerial tramway', '194?', 'Austria', 'Mittersill', '80 m', 'Two pylons for a tramway that never went in service and was demolished in the 1950s. One of the pylons was built of timber, the other of steel.'], ['Singapore cable car', '1972', 'Singapore', 'Singapore', '80 m', 'Pylon II'], ['3S Aerial Tramway', '2004', 'Austria', 'Kitzbühel', '80 m', 'One pylon'], ['Torre Sant Sebastia', '1931', 'Spain', 'Barcelona', '78 m', 'Terminal of harbour aerial tramway'], ['Roosevelt Island Tramway', '1976', 'USA', 'New York City', '76 m', 'Central pylon of commuter tramway'], ['Wendelstein Aerial Tramway', '1970', 'Germany', 'Bayerischzell-Osterhofen', '75 m', ''], ['Vinpearl Cable Car', '2007', 'Vietnam', 'Nha Trang', '75 m', '7 pylons standing in the sea. Total height from sea bed is 115 m'], ['Sandia Peak Tramway', '1965', 'USA', 'Albuquerque', '70.7 m', 'Pylon 1, inclined at an angle of 18 degrees'], ['Eibsee Aerial Tramway', '1962', 'Germany', 'Garmisch-Partenkirchen', '65 m', 'Pylon I']], 'name': 'csv/203-csv/375.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Name', 'Year built', 'Country', 'Town', 'Height', 'Remarks']"
        ],
        [
         "10",
         "how many districts are there in virginia?",
         "{'header': ['District', 'Incumbent', 'Party', 'First\\\\nelected', 'Result', 'Candidates'], 'rows': [['Virginia 1', 'Thomas Newton, Jr.', 'Adams-Clay Republican', '1801', 'Re-elected', 'Thomas Newton, Jr.'], ['Virginia 2', 'Arthur Smith', 'Crawford Republican', '1821', 'Retired\\\\nJacksonian gain', 'James Trezvant (J) 75.7%\\\\nRichard Eppes (DR) 24.3%'], ['Virginia 3', 'William S. Archer', 'Crawford Republican', '1820 (special)', 'Re-elected', 'William S. Archer (J) 100%'], ['Virginia 4', 'Mark Alexander', 'Crawford Republican', '1819', 'Re-elected', 'Mark Alexander (J)'], ['Virginia 5', 'John Randolph', 'Crawford Republican', '1799\\\\n1819', 'Re-elected', 'John Randolph (J) 100%'], ['Virginia 6', 'George Tucker', 'Crawford Republican', '1819', 'Retired\\\\nJacksonian gain', 'Thomas Davenport (J) 53.9%\\\\nJames Lanier 22.6%\\\\nBarzillai Graves 16.3%\\\\nJohn D. Urquhart 7.2%'], ['Virginia 7', 'Jabez Leftwich', 'Crawford Republican', '1821', 'Lost re-election\\\\nJacksonian gain', 'Nathaniel H. Claiborne (J) 51.4%\\\\nJabez Leftwich (C-DR) 48.6%'], ['Virginia 8', 'Burwell Bassett', 'Crawford Republican', '1805\\\\n1821', 'Re-elected', 'Burwell Bassett (J) 95.3%\\\\nServant Jones (DR) 4.5%\\\\nReuben Washer 0.2%'], ['Virginia 9', 'Andrew Stevenson', 'Crawford Republican', '1821', 'Re-elected', 'Andrew Stevenson (J) 100%'], ['Virginia 10', 'William C. Rives', 'Crawford Republican', '1823', 'Re-elected', 'William C. Rives (J) 100%'], ['Virginia 11', 'Philip P. Barbour', 'Crawford Republican', '1814 (special)', 'Retired\\\\nAdams gain', 'Robert Taylor (A) 100%'], ['Virginia 12', 'Robert S. Garnett', 'Crawford Republican', '1817', 'Re-elected', 'Robert S. Garnett (J) 68.5%\\\\nJohn H. Upshaw 31.5%'], ['Virginia 13', 'John Taliaferro', 'Crawford Republican', '1824 (special)', 'Re-elected', 'John Taliaferro (A) 63.3%\\\\nJohn Hooe (F) 26.7%'], ['Virginia 14', 'Charles F. Mercer', 'Crawford Republican', '1817', 'Re-elected', 'Charles F. Mercer (A)'], ['Virginia 15', 'John S. Barbour', 'Crawford Republican', '1823', 'Re-elected', 'John S. Barbour (J) 53.7%\\\\nThomas Marshall (F) 46.3%'], ['Virginia 16', 'James Stephenson', 'Federalist', '1821', 'Retired\\\\nAdams gain', 'William Armstrong (A) 57.1%\\\\nEdward Colston (F) 42.9%'], ['Virginia 17', 'Jared Williams', 'Crawford Republican', '1819', 'Retired\\\\nAdams gain', 'Alfred H. Powell (A) 42.0%\\\\nWilliam Steenergen (DR) 21.5%\\\\nAugustine C. Smith (DR) 20.3%\\\\nSamuel Kercheval (DR) 13.6%\\\\nRobert Allen (DR) 2.6%'], ['Virginia 18', 'Joseph Johnson', 'Jackson Republican', '1823', 'Re-elected', 'Joseph Johnson (J) 62.0%\\\\nPhillip Doddridge (F) 38.0%'], ['Virginia 19', 'William McCoy', 'Crawford Republican', '1811', 'Re-elected', 'William McCoy (J) 70.2%\\\\nDaniel Sheffey (F) 29.8%'], ['Virginia 20', 'John Floyd', 'Crawford Republican', '1817', 'Re-elected', 'John Floyd (J) 84.7%\\\\nAllen Taylor (F) 15.3%'], ['Virginia 21', 'William Smith', 'Crawford Republican', '1821', 'Re-elected', 'William Smith (J) 55.2%\\\\nJames Lovell (DR) 44.8%'], ['Virginia 22', 'Alexander Smyth', 'Crawford Republican', '1817', 'Retired\\\\nAdams gain', 'Benjamin Estil (A) 58.9%\\\\nJoseph Crockett (DR) 32.0%\\\\nWilliam Graham (DR) 9.1%']], 'name': 'csv/204-csv/109.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['District', 'Incumbent', 'Party', 'First\\\\nelected', 'Result', 'Candidates']"
        ],
        [
         "11",
         "what is the number of tv shows that charmaine sheh has appeared on?",
         "{'header': ['Year', 'Name of show', 'Episodes', 'Other guests', 'Winner(s)'], 'rows': [['1997', 'Super Trio Series 2: Movie Buff Championship', '18', 'Florence Kwok, Joey Leung, Shen Yu, Eddie Ng, Athena Chu', 'Charmaine Sheh'], ['2000', 'The Super Trio Show', '06', 'Julian Cheung, Calvin Choy, Sherming Yiu, Yuen Wah, Liz Kong', 'Charmaine Sheh, Julian Cheung'], ['2002', 'A Trio Delights', '03', 'Timmy Hung, Ken Wong, Stephanie Che, Louis Yuen, Cutie Mui', 'Louis Yuen'], ['2004', 'The Super Trio Continues', '07', 'Michael Tao, Kenix Kwok, Cheung Tat-Ming, Wong Ceng, Nnadia Chan', 'Charmaine Sheh, Michael Tao'], ['2007', 'Foodie 2 Shoes', '19, 20', 'Chin Ka Lok, Edmond Leung, Vanessa Yeung', 'Charmaine Sheh, Chin Ka Lok'], ['2008', 'Super Trio Supreme', '01', 'Bosco Wong, Michael Miu, Cutie Mui, Johnny Tang, Krystal Tin, Tiffany Hew, Cleo Tay, Crystal Wong', 'Charmaine Sheh, Cutie Mui'], ['2009', 'Are You Smarter Than a 5th Grader?', '05, 06', '', 'HK$175,000 (Levels 8/11)'], ['2010', 'Super Trio Game Master', '20', 'Moses Chan, Kenneth Ma, Raymond Wong, Lee Heung Kam, Louis Yuen, Selena Li, Susan Tse, Lee Kwok Leung, Edwin Siu, Elaine Yiu, Yoyo Chen, Charmaine Li', 'Tie'], ['2011', 'All Star Glam Exam', '08', 'Ekin Cheng, Eric Kot, Fala Chen', 'Charmaine Sheh']], 'name': 'csv/203-csv/631.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Year', 'Name of show', 'Episodes', 'Other guests', 'Winner(s)']"
        ],
        [
         "12",
         "amazon is at the top of the chart, but what is the name below it?",
         "{'header': ['Pennant', 'Name', 'Hull builder', 'Ordered', 'Laid down', 'Launched', 'Accepted into service', 'Commissioned', 'Est. building cost', 'Fate'], 'rows': [['F169', 'Amazon', 'Vosper Thornycroft, Woolston', '26 March 1969', '6 November 1969', '26 April 1971', '19 July 1974', '11 May 1974', '£16.8M', 'To Pakistan as Babur'], ['F170', 'Antelope', 'Vosper Thornycroft', '11 May 1970', '23 March 1971', '16 March 1972', '30 June 1975', '16 July 1975', '£14.4M', 'Bombed by Argentine A-4 Skyhawks on 23 May 1982 and sank following day in San Carlos Water'], ['F172', 'Ambuscade', 'Yarrow Shipbuilders, Scotstoun', '11 November 1971', '1 September 1971', '18 January 1973', '23 August 1975', '5 September 1975', '£16.5M', 'To Pakistan as Tariq'], ['F173', 'Arrow', 'YSL', '11 November 1971', '28 September 1972', '5 February 1974', '16 May 1975', '29 July 1976', '£20.2M', 'To Pakistan as Khaibar'], ['F171', 'Active', 'Vosper Thornycroft', '11 May 1970', '21 July 1971', '23 November 1972', '2 June 1977', '17 June 1977', '£24.1M', 'To Pakistan as Shah Jahan'], ['F174', 'Alacrity', 'YSL', '11 November 1971', '5 March 1973', '18 September 1974', '2 April 1977', '2 July 1977', '£23.8M', 'To Pakistan as Badr'], ['F184', 'Ardent', 'YSL', '11 November 1971', '26 February 1974', '9 May 1975', '10 September 1977', '14 October 1977', '£26.3M', 'Bombed by Argentine A-4 Skyhawks on 21 May 1982 in San Carlos Water and sank following day in Grantham Sound'], ['F185', 'Avenger', 'YSL', '11 November 1971', '30 October 1974', '20 November 1975', '15 April 1978', '15 April 1978', '£27.7M', 'To Pakistan as Tippu Sultan']], 'name': 'csv/204-csv/568.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Pennant', 'Name', 'Hull builder', 'Ordered', 'Laid down', 'Launched', 'Accepted into service', 'Commissioned', 'Est. building cost', 'Fate']"
        ],
        [
         "13",
         "which year had the most titles released?",
         "{'header': ['Release', 'Artist', 'Title', 'Notes', 'Album'], 'rows': [['2004', 'Hiroshi Itsuki feat. Rimi Natsukawa', \"Deigo to Hanasu (デイゴとはまなす Talking with a Tiger's Claw Flower?)\", '', 'Onna no Ehon'], ['2005', 'Chikuzen Sato with Rimi Natsukawa', 'Boku no Mune de Oyasumi (僕の胸でおやすみ Goodbye with My Heart?)', 'Features on \"Rimits: Best Duet Songs\" (2006)', 'The Selection of Cornerstones 1995-2004'], ['2005', 'Rimi Natsukawa', \"'Aa Kōshien' Kimi yo Hachigatsu ni Atsuku Nare (「あゝ甲子園」君よ八月に熱くなれ You Make Me Hot in August (from Ah, Kōshien)?)\", '', 'Ningen Manyōka: Yū Aku Kashishū'], ['2005', 'Kaoru Kurosawa duet with Rimi Natsukawa', 'Manten no Hoshi no Yoru (満天の星の夜 Night with a Sky Full of Stars?)', 'Features on \"Rimits: Best Duet Songs\" (2006)', 'Love Anthem'], ['2006', 'Andrea Bocelli duet with Rimi Natsukawa', \"Somos Novios (Ai no Yume) (ソモス・ノビオス～愛の夢 It's Impossible (Dream of Love)?)\", 'Features on \"Umui Kaji\" (2007)', 'Amore (Japanese Edition)'], ['2008', 'Taiyo Yamazawa presents Rimi Natsukawa', 'Utabito (歌人 Singer?)', '', 'Music Tree'], ['2009', 'Chage with Rimi Natsukawa', 'Boku wa Dō Kana (僕はどうかな What Should I Do?)', '', 'Many Happy Returns'], ['2009', 'Rimi Natsukawa', \"Tada Sore Dake (ただそれだけ It's Only That?)\", '', 'Katsuhisa Hattori']], 'name': 'csv/204-csv/643.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Release', 'Artist', 'Title', 'Notes', 'Album']"
        ],
        [
         "14",
         "who was the first to take office?",
         "{'header': ['#', 'Menteri Besar', 'Took office', 'Left office', 'Party'], 'rows': [['1', 'Jaafar Mohamed', '1886', 'July 1890', 'No party'], ['2', 'Mohamed Mahbob', 'June 1920', '1922', 'No party'], ['3', 'Abdullah Jaafar', 'September 1923', '1928', 'No party'], ['4', 'Mustapha Jaafar', 'September 16, 1928', 'November 23, 1931', 'No party'], ['5', 'Abdul Hamid Yusof', 'November 23, 1931', 'December 28, 1934', 'No party'], ['6', 'Ungku Abdul Aziz Abdul Majid', 'April 1935', 'June 1, 1947', 'No party'], ['7', 'Onn Jaafar', 'June 1, 1947', 'May 18, 1950', 'No party'], ['8', 'Syed Abdul Kadir Mohamed', 'February 18, 1952', 'June 5, 1955', 'No party'], ['9', 'Wan Idris Ibrahim', 'October 1, 1955', 'August 31, 1957', 'No party']], 'name': 'csv/204-csv/668.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['#', 'Menteri Besar', 'Took office', 'Left office', 'Party']"
        ],
        [
         "15",
         "which composer produced his title after 2001?",
         "{'header': ['Composer', 'Title', 'Genre', 'Date', 'Notes'], 'rows': [['Flor Alpaerts', 'Salome', 'incidental\\xa0music', '', ''], ['Granville Bantock', 'Dance of the\\\\nSeven Veils', 'incidental music', '1918', 'staged London, 1918'], ['Leonard Bernstein', 'Salome', 'incidental music', '1955', 'chamber orchestra with 8 players and vocal soloists; withdrawn'], ['Peter\\xa0Maxwell\\xa0Davies', 'Salome', 'ballet', '1978', 'premiered Copenhagen, 10 November 1978; Danish Radio Concert Orchestra, conducted by János Fürst; scenario and choreography by Flemming Flindt'], ['Pete Doherty', 'Salome', 'popular music', '2009', 'appears on his album Grace/Wastelands'], ['Alexander Glazunov', 'Introduction and Dance, Op. 90', 'incidental music', '1908', ''], ['Henry Hadley', 'Salome, Op. 55', 'symphonic poem', '1905', \"this was written after Hadley had seen a production of Oscar Wilde's play, and was a favourite among his own compositions\"], ['Alexander Krein', 'Salome, Op. 19', 'symphonic poem', '1929', ''], ['Constant Lambert', 'Salome', 'incidental music', '1929', 'clarinet, cello, trumpet, percussion; written for a performance staged in Cambridge by Terence Gray, with choreography by Ninette de Valois; staged again November 1931; a suite was arranged by Giles Easterbrook in 1998 and recorded in 2000'], ['Antoine Mariotte', 'Salomé', 'opera', '1905', \"premiered 1908; he was involved in a debate with Richard Strauss to prove that his music was written earlier than Strauss's version, also written in 1905\"], ['Emil Petrovics', 'Salome', 'ballet', '1978', 'flute, trumpet, harp and percussion'], ['Richard Strauss', 'Salome, Op. 54', 'opera', '1905', 'trans. Hedwig Lachmann; premiered Dresden 1905. This opera is by far the best known musical adaptation of a work of Oscar Wilde.'], ['Alexander\\xa0Tcherepnin', 'Salome', 'incidental music', '', '']], 'name': 'csv/204-csv/969.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Composer', 'Title', 'Genre', 'Date', 'Notes']"
        ],
        [
         "16",
         "which player ranked the most?",
         "{'header': ['Rank', 'Player', 'County', 'Tally', 'Total', 'Opposition'], 'rows': [['1', 'Nicky English', 'Tipperary', '2-12', '18', 'Antrim'], ['2', 'Mark Corrigan', 'Offaly', '3-7', '16', 'Kilkenny'], ['3', 'Joe Hennessy', 'Kerry', '3-5', '14', 'Limerick'], ['3', 'Finbarr Delaney', 'Cork', '1-11', '14', 'Waterford'], ['5', 'Nicky English', 'Tipperary', '0-13', '13', 'Waterford'], ['5', 'Adrian Ronan', 'Kilkenny', '1-10', '13', 'Westmeath'], ['7', 'Nicky English', 'Tipperary', '2-5', '11', 'Limerick'], ['7', 'Danny McNaughton', 'Antrim', '2-5', '11', 'Down'], ['9', 'M. J. Ryan', 'Dublin', '1-7', '10', 'Laois'], ['10', 'Gary Kirby', 'Limerick', '1-6', '9', 'Kerry'], ['10', 'Pat Murphy', 'Waterford', '3-0', '9', 'Cork']], 'name': 'csv/204-csv/952.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Player', 'County', 'Tally', 'Total', 'Opposition']"
        ],
        [
         "17",
         "how long after fairfield was no. 1 built?",
         "{'header': ['Name', 'Date built', 'Builder', 'Works No.', 'Wheels', 'Cylinders', 'Notes', 'Withdrawn'], 'rows': [['Veteran', '1847', '?', '?', '0-6-0', 'Inside', 'arr. 1847', '?'], ['Fairfield', '1847', '?', '?', '0-6-0', 'Inside', 'arr. 1847', '?'], ['Waverley', '?', 'Henry Hughes of Loughborough', '?', '0-4-0ST', 'Outside', '-', '1889'], ['Bee', '?', '?', '?', '0-6-0T', '?', '-', '?'], ['Spider', '?', '?', '?', '0-6-0T', '?', '-', '?'], ['Gillingham', '?', 'Aveling and Porter', '?', '0-6-0TG', '?', 'arr. 1893', '1893'], ['No.1', '1880', 'Hunslet', '231', '0-6-0ST', 'Inside', 'arr. 1893', '1923'], ['No.2', '1898', 'Peckett', '696', '0-4-0ST', 'Outside', 'arr. 1904', '1923']], 'name': 'csv/204-csv/476.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Name', 'Date built', 'Builder', 'Works No.', 'Wheels', 'Cylinders', 'Notes', 'Withdrawn']"
        ],
        [
         "18",
         "what is the difference in runners-up from coleraine academical institution and royal school dungannon?",
         "{'header': ['School', 'Location', 'Outright Titles', 'Shared Titles', 'Runners-Up', 'Total Finals', 'Last Title', 'Last Final'], 'rows': [['Methodist College Belfast', 'Belfast', '35', '2', '25', '62', '2014', '2014'], ['Royal Belfast Academical Institution', 'Belfast', '29', '4', '21', '54', '2007', '2013'], ['Campbell College', 'Belfast', '23', '4', '12', '39', '2011', '2011'], ['Coleraine Academical Institution', 'Coleraine', '9', '0', '24', '33', '1992', '1998'], ['The Royal School, Armagh', 'Armagh', '9', '0', '3', '12', '2004', '2004'], ['Portora Royal School', 'Enniskillen', '6', '1', '5', '12', '1942', '1942'], ['Bangor Grammar School', 'Bangor', '5', '0', '4', '9', '1988', '1995'], ['Ballymena Academy', 'Ballymena', '3', '0', '6', '9', '2010', '2010'], ['Rainey Endowed School', 'Magherafelt', '2', '1', '2', '5', '1982', '1982'], ['Foyle College', 'Londonderry', '2', '0', '4', '6', '1915', '1915'], ['Belfast Royal Academy', 'Belfast', '1', '3', '5', '9', '1997', '2010'], ['Regent House Grammar School', 'Newtownards', '1', '1', '2', '4', '1996', '2008'], ['Royal School Dungannon', 'Dungannon', '1', '0', '4', '5', '1907', '1975'], ['Annadale Grammar School (now Wellington College)', 'Belfast', '1', '0', '1', '2', '1958', '1978'], ['Ballyclare High School', 'Ballyclare', '1', '0', '1', '2', '1973', '2012'], [\"Belfast Boys' Model School\", 'Belfast', '1', '0', '0', '1', '1971', '1971'], ['Grosvenor High School', 'Belfast', '1', '0', '0', '1', '1983', '1983'], ['Wallace High School', 'Lisburn', '0', '0', '4', '4', 'N/A', '2007'], ['Derry Academy', 'Derry', '0', '0', '2', '2', 'N/A', '1896'], ['Dalriada School', 'Ballymoney', '0', '0', '1', '1', 'N/A', '1993'], ['Galway Grammar School', 'Galway', '0', '0', '1', '1', 'N/A', '1887'], ['Lurgan College', 'Lurgan', '0', '0', '1', '1', 'N/A', '1934'], ['Omagh Academy', 'Omagh', '0', '0', '1', '1', 'N/A', '1985'], ['Sullivan Upper School', 'Holywood', '0', '0', '1', '1', 'N/A', '2014']], 'name': 'csv/203-csv/362.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['School', 'Location', 'Outright Titles', 'Shared Titles', 'Runners-Up', 'Total Finals', 'Last Title', 'Last Final']"
        ],
        [
         "19",
         "how many times has germany won bronze?",
         "{'header': ['Year', 'Place', 'Gold', 'Silver', 'Bronze'], 'rows': [['1970', 'Phoenix', 'United States of America\\\\nSally Carroll\\\\nLucile Chambliss\\\\nBarbara Hile', 'Soviet Union\\\\nNadezda Ibragimova\\\\nNina Rasskazova\\\\nNina Stoliarova', 'Federal Republic of Germany\\\\nOrtrud Feickert\\\\nKarin Fitzner\\\\nRuth Kasten'], ['1974', 'Thun', 'Soviet Union\\\\nGalina Zarikova\\\\nZinaida Simonian\\\\nNina Stoliarova', 'Czechoslovakia\\\\nTereza Bohinska\\\\nBedriska Hykova\\\\nKatarina Pastorova', 'Australia\\\\nJudith Harrison\\\\nEnid Newton\\\\nGloria Vause'], ['1978', 'Seoul', 'Denmark\\\\nKirsten Broge\\\\nBonnie Bruun\\\\nAase Havsteen', 'Australia\\\\nJulie Aitken\\\\nPatricia Dench\\\\nLynne Uden', 'United States of America\\\\nSally Carroll\\\\nKimberly Dyer\\\\nRuby Fox'], ['1982', 'Caracas', 'Soviet Union\\\\nMarina Dobrantcheva\\\\nInna Rose\\\\nAuksne Treinite', 'Hungary\\\\nPalma Balogh\\\\nMarta Kotroczo\\\\nGabriella Kanyai', \"People's Republic of China\\\\nJianmin Gao\\\\nZhifang Wen\\\\nCui Qing Yang\"], ['1986', 'Suhl', 'Soviet Union\\\\nMarina Dobrantcheva\\\\nIrina Kotcherova\\\\nNino Salukvadze', 'France\\\\nMartine Guepin\\\\nEvelyne Manchon\\\\nCorine Serra-Tosio', 'Albania\\\\nDiana Mata\\\\nEmanuela Delilaj\\\\nEdlira Shyti'], ['1990', 'Moscow', 'Soviet Union\\\\nYauheniya Haluza\\\\nMarina Logvinenko\\\\nNino Salukvadze', 'Sweden\\\\nKerstin Bodin\\\\nBritt Marie Ellis\\\\nChris Kajd', \"People's Republic of China\\\\nHaiying Liu\\\\nDuihong Li\\\\nMeifang Qian\"], ['1994', 'Milan', \"People's Republic of China\\\\nXiaoping Fan\\\\nDuihong Li\\\\nLina Wang\", 'Korea\\\\nSoon Hee Boo\\\\nSun Bok Lee\\\\nJung Hee Park', 'Belarus\\\\nZhanna Shitik\\\\nYauheniya Haluza\\\\nYuliya Siniak'], ['1998', 'Barcelona', \"People's Republic of China\\\\nYeqing Cai\\\\nLuna Tao\\\\nYi Sun\", 'Korea\\\\nEun Kyung Shin\\\\nSoon Hee Boo\\\\nJoo Hyung Seo', 'Mongolia\\\\nMunkhbayar Dorjsuren\\\\nOyun Davaajantsan\\\\nGundegmaa Otryad'], ['2002', 'Lahti', \"People's Republic of China\\\\nLuna Tao\\\\nYing Chen\\\\nDuihong Li\", 'Russia\\\\nIrina Dolgatcheva\\\\nGalina Beliaeva\\\\nSvetlana Smirnova', 'United States of America\\\\nElizabeth Callahan\\\\nRebecca Snyder\\\\nSandra Uptagrafft'], ['2006', 'Zagreb', \"People's Republic of China\\\\nYing Chen\\\\nFengji Fei\\\\nDuihong Li\", 'Belarus\\\\nLiudmila Chabatar\\\\nZhanna Shapialevich\\\\nYauheniya Haluza', 'Germany\\\\nMunkhbayar Dorjsuren\\\\nStefanie Thurmann\\\\nClaudia Verdicchio'], ['2010', 'Munich', 'Russia\\\\nYulia Alipova\\\\nKira Klimova\\\\nGalina Beliaeva', 'Serbia\\\\nZorana Arunovic\\\\nJasna Sekaric\\\\nJelena Arunovic', 'Czech Republic\\\\nLenka Maruskova\\\\nMichaela Musilova\\\\nPetra Hykova'], ['2014', 'Granada', 'TBD', 'TBD', 'TBD'], ['2018', 'Changwon', 'TBD', 'TBD', 'TBD']], 'name': 'csv/203-csv/554.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Year', 'Place', 'Gold', 'Silver', 'Bronze']"
        ],
        [
         "20",
         "list two pylons that are at most, 80 m in height.",
         "{'header': ['Name', 'Year built', 'Country', 'Town', 'Height', 'Remarks'], 'rows': [['Glacial Aerial Tramway Kaprun III', '1966', 'Austria', 'Kaprun', '113.6 m', 'The tallest pylon is on the third section'], ['Mississippi Aerial River Transit', '1984', 'USA', 'New Orleans', '109 m', 'The tallest pylon on a gondola lift; on 87 m pile foundations; demolished 1994'], ['Torre Jaume I', '1931', 'Spain', 'Barcelona', '107 m', 'Intermediate stop of the harbour aerial tramway, also observation tower'], ['Gant Hohtaelli aerial tramway', '', 'Switzerland', 'Zermatt', '94 m', 'One pylon'], ['London Emirates Air Line', 'Early 2012', 'UK', 'London', '88 m', 'North Main Tower. River Thames aerial crossing between Greenwich Peninsular and Royal Docks'], ['Singapore cable car', '1972', 'Singapore', 'Singapore', '88 m', 'Pylon I'], ['Eibsee Aerial Tramway', '1962', 'Germany', 'Garmisch-Partenkirchen', '85 m', 'Pylon II'], ['Nizhny Novgorod Volga Aerial Tramway, Tower 4 & 5', '2012', 'Russia', 'Nizhny Novgorod', '82 m', ''], ['Mittersill goods aerial tramway', '194?', 'Austria', 'Mittersill', '80 m', 'Two pylons for a tramway that never went in service and was demolished in the 1950s. One of the pylons was built of timber, the other of steel.'], ['Singapore cable car', '1972', 'Singapore', 'Singapore', '80 m', 'Pylon II'], ['3S Aerial Tramway', '2004', 'Austria', 'Kitzbühel', '80 m', 'One pylon'], ['Torre Sant Sebastia', '1931', 'Spain', 'Barcelona', '78 m', 'Terminal of harbour aerial tramway'], ['Roosevelt Island Tramway', '1976', 'USA', 'New York City', '76 m', 'Central pylon of commuter tramway'], ['Wendelstein Aerial Tramway', '1970', 'Germany', 'Bayerischzell-Osterhofen', '75 m', ''], ['Vinpearl Cable Car', '2007', 'Vietnam', 'Nha Trang', '75 m', '7 pylons standing in the sea. Total height from sea bed is 115 m'], ['Sandia Peak Tramway', '1965', 'USA', 'Albuquerque', '70.7 m', 'Pylon 1, inclined at an angle of 18 degrees'], ['Eibsee Aerial Tramway', '1962', 'Germany', 'Garmisch-Partenkirchen', '65 m', 'Pylon I']], 'name': 'csv/203-csv/375.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Name', 'Year built', 'Country', 'Town', 'Height', 'Remarks']"
        ],
        [
         "21",
         "why type of genre was peter maxwell davies' work that was the same as emil petrovics'",
         "{'header': ['Composer', 'Title', 'Genre', 'Date', 'Notes'], 'rows': [['Flor Alpaerts', 'Salome', 'incidental\\xa0music', '', ''], ['Granville Bantock', 'Dance of the\\\\nSeven Veils', 'incidental music', '1918', 'staged London, 1918'], ['Leonard Bernstein', 'Salome', 'incidental music', '1955', 'chamber orchestra with 8 players and vocal soloists; withdrawn'], ['Peter\\xa0Maxwell\\xa0Davies', 'Salome', 'ballet', '1978', 'premiered Copenhagen, 10 November 1978; Danish Radio Concert Orchestra, conducted by János Fürst; scenario and choreography by Flemming Flindt'], ['Pete Doherty', 'Salome', 'popular music', '2009', 'appears on his album Grace/Wastelands'], ['Alexander Glazunov', 'Introduction and Dance, Op. 90', 'incidental music', '1908', ''], ['Henry Hadley', 'Salome, Op. 55', 'symphonic poem', '1905', \"this was written after Hadley had seen a production of Oscar Wilde's play, and was a favourite among his own compositions\"], ['Alexander Krein', 'Salome, Op. 19', 'symphonic poem', '1929', ''], ['Constant Lambert', 'Salome', 'incidental music', '1929', 'clarinet, cello, trumpet, percussion; written for a performance staged in Cambridge by Terence Gray, with choreography by Ninette de Valois; staged again November 1931; a suite was arranged by Giles Easterbrook in 1998 and recorded in 2000'], ['Antoine Mariotte', 'Salomé', 'opera', '1905', \"premiered 1908; he was involved in a debate with Richard Strauss to prove that his music was written earlier than Strauss's version, also written in 1905\"], ['Emil Petrovics', 'Salome', 'ballet', '1978', 'flute, trumpet, harp and percussion'], ['Richard Strauss', 'Salome, Op. 54', 'opera', '1905', 'trans. Hedwig Lachmann; premiered Dresden 1905. This opera is by far the best known musical adaptation of a work of Oscar Wilde.'], ['Alexander\\xa0Tcherepnin', 'Salome', 'incidental music', '', '']], 'name': 'csv/204-csv/969.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Composer', 'Title', 'Genre', 'Date', 'Notes']"
        ],
        [
         "22",
         "what is the difference (in years) between when the royal blue began and the year the crusader began?",
         "{'header': ['Operators', 'Named trains', 'Destination', 'Year begun', 'Year discontinued'], 'rows': [['Baltimore and Ohio', 'Capitol Limited', 'Chicago, Illinois via Washington, D.C. and Pittsburgh, Pennsylvania', '1923', '1958*'], ['Baltimore and Ohio', 'Metropolitan Special', 'St. Louis, Missouri via Washington, D.C. and Cincinnati, Ohio', 'ca. 1920', '1958*'], ['Baltimore and Ohio', 'National Limited', 'St. Louis, Missouri via Washington, D.C. and Cincinnati, Ohio', '1925', '1958*'], ['Baltimore and Ohio', 'Royal Blue', 'Washington, D.C.', '1890', '1958'], ['Central Railroad of New Jersey', 'Blue Comet', 'Atlantic City, New Jersey', '1929', '1941'], ['Reading Railroad with the Central Railroad of New Jersey', 'Crusader', 'Philadelphia, Pennsylvania', '1937', '1967'], ['Reading Railroad with the Central Railroad of New Jersey', 'Harrisburg Special', 'Harrisburg, Pennsylvania', '', ''], ['Reading Railroad with the Central Railroad of New Jersey', 'Queen of the Valley', 'Harrisburg, Pennsylvania', '', '1967'], ['Reading Railroad with the Central Railroad of New Jersey', 'Wall Street', 'Philadelphia, Pennsylvania', '', ''], ['Reading Railroad with the Central Railroad of New Jersey', 'Williamsporter', 'Williamsport, Pennsylvania', '', '']], 'name': 'csv/204-csv/336.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Operators', 'Named trains', 'Destination', 'Year begun', 'Year discontinued']"
        ],
        [
         "23",
         "who received the least amount of votes?",
         "{'header': ['Riding', 'Candidate', 'Gender', 'Residence', 'Occupation', 'Votes', '%', 'Rank', 'Biographical notes'], 'rows': [['Cape Breton—Canso', 'Mark MacNeill', 'M', 'Inverness', 'Government and Business Policy Advisor', '7,660', '21.1', '3rd', \"Served in Ottawa as a consultant with National Advisory Board on Science and Technology, with the Treasury Board Secretariat and the Solicitor General's Aboriginal Policing Secretariat.\"], ['Central Nova', 'Mary Louise Lorefice', 'F', 'Antigonish', 'Retired educator', '7,659', '19.6', '3rd', 'Lorefice is a retired teacher from Antigonish, who has lived in the community for 38 years.'], ['Cumberland—Colchester—Musquodoboit Valley', 'Karen Olsson', 'F', 'North River', 'Stay-at-home Mother', '4,874', '12.3', '2nd', ''], ['Dartmouth—Cole Harbour', 'Brad Pye', 'M', 'Ottawa, ON', 'Senior Political Party Program Officer', '12,793', '31.5', '2nd', 'Pye is an international development worker and son of former Dartmouth North MLA Jerry Pye.'], ['Halifax', 'Megan Leslie', 'F', 'Halifax', 'Community Legal Worker', '19,252', '42.7', '1st', ''], ['Halifax West', 'Tamara Lorincz', 'F', 'Halifax', 'Director of Nova Scotia Environment Network', '12,201', '29.6', '2nd', 'An environmentalist.'], ['Kings—Hants', 'Carol E. Harris', 'F', 'Wolfville', 'University Professor', '8,291', '22.0', '3rd', \"She was the NDP's candidate in the 2000 election in Esquimalt—Juan de Fuca.\"], ['Sackville—Eastern Shore', 'Peter Stoffer', 'M', 'Windsor Junction', 'Parliamentarian', '24,279', '61.4', '1st', 'Stoffer has been the incumbent MP since 1997.'], [\"South Shore—St. Margaret's\", 'Gordon S. Earle', 'M', 'Upper Tantallon', 'Retired Public Servant', '13,456', '33.7', '2nd', 'Earle is the former federal MP for Halifax West (1997–2000). Has run in this riding unsuccessfully in 2004 and 2006.'], ['Sydney—Victoria', 'Wayne McKay', 'M', 'Sydney', 'Teacher', '8,559', '24.4', '2nd', ''], ['West Nova', 'George Barron', 'M', 'Bear River', 'Paramedic', '7,097', '16.9', '3rd', 'Barron was born near Paris, Ontario, he has been a paramedic for 22 years. He was nominated on October 28, 2007.']], 'name': 'csv/204-csv/786.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Riding', 'Candidate', 'Gender', 'Residence', 'Occupation', 'Votes', '%', 'Rank', 'Biographical notes']"
        ],
        [
         "24",
         "what is the next highest hard drive available after the 30gb model?",
         "{'header': ['Component', 'Model 01', 'Model 01+', 'Model 02', 'Model e2', 'Model 2+ (Pre-production)', 'model 03 (China Copy)'], 'rows': [['CPU', 'Transmeta Crusoe 1\\xa0GHz', 'Transmeta Crusoe 1\\xa0GHz', 'Via C7M ULV 1.6\\xa0GHz', 'Via C7M ULV 1.6\\xa0GHz', 'Intel Atom Z540 1.86\\xa0GHz', 'Intel atom Z550 1.2\\xa0GHz dual core'], ['RAM', '256MB DDR', '512MB DDR', '1GB DDR2', '1GB DDR2', '2GB DDR2', '2GB DDR2'], ['Hard Drive', '20GB HDD', '30GB HDD', '120GB HDD or 64GB SSD', '120GB HDD or 64GB SSD', '120GB HDD or 64GB SSD', '120GB HDD or 64GB SSD'], ['Display', '5\" Transflective 800x480 LCD', '5\" Transflective 800x480 LCD', '5\" 800x480 LCD', '5\" 800x480 LCD', '5\" active matrix 800x480 OLED', '4.8\" active matrix 1024X600 OLED'], ['USB', '1.1', '2.0', '2.0', '2.0', '2.0', '2.0'], ['Wi-Fi', '802.11b', '802.11b', '802.11a/b/g', '802.11a/b/g', '802.11a/b/g', '802.11a/b/g/n'], ['WWAN', 'n/a', 'n/a', 'EVDO from Sprint or Verizon', 'HSDPA', 'EV-DO and HSPA', 'HSDPA 3G'], ['Bluetooth', '1.1', '1.1', '2.0', '2.0', '2.0', '2.1'], ['Wacom', 'Yes', 'Yes (Improved accuracy)', 'Yes', 'Yes', 'Yes', 'unknown'], ['GPU', 'Silicon motion Lynx 3DM+', 'Silicon motion Lynx 3DM+', 'VIA VX700', 'VIA VX700', 'Intel GMA500', 'Intel GMA500'], ['Removable Battery', '4,000 mAh or 8,000 mAh', '4,000 mAh or 8,000 mAh', '4,500 mAh or 9,000 mAh', '4,500 mAh or 9,000 mAh', '4,500 mAh or 9,000 mAh', '4,500 mAh or 9,000 mAh'], ['Battery Type', 'lithium polymer', 'Lithium Polymer', 'lithium ion polymer', 'lithium ion polymer', 'lithium ion polymer', 'unknown'], ['Docking Cable', 'USB 1.1', 'USB 2.0', 'replaced by dongle or dock', 'replaced by dongle or dock', 'replaced by dongle or dock', 'replaced by dongle or dock'], ['Dock', 'Zinc stand', 'Zinc stand', 'Gloss Black w/ optical drive', 'Gloss Black w/ optical drive', 'Gloss Black w/ optical drive', 'Gloss Black w/ optical drive'], ['Ethernet', '10BaseT', '100BaseT', '100BaseT', '100BaseT', '100BaseT', '100BaseT'], ['Dongle', '', '', 'RJ45 & VGA', 'RJ45 & VGA', 'unknown', 'unknown'], ['Keyboard', '57 key', '57 key', '58 key', '58 key', '58 key', '58 key'], ['Weight', '397g', '397g', '413g*', '413g*', '413g*', '426g*']], 'name': 'csv/204-csv/451.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Component', 'Model 01', 'Model 01+', 'Model 02', 'Model e2', 'Model 2+ (Pre-production)', 'model 03 (China Copy)']"
        ],
        [
         "25",
         "which mountain peak has a prominence more than 10,000 ft?",
         "{'header': ['Rank', 'Mountain Peak', 'Mountain Range', 'Elevation', 'Prominence', 'Isolation', 'Location'], 'rows': [['1', 'Mount Whitney', 'Sierra Nevada', '14,505\\xa0ft\\\\n4421\\xa0m', '10,080\\xa0ft\\\\n3072\\xa0m', '1,646\\xa0mi\\\\n2,649\\xa0km', '36°34′43″N 118°17′31″W\\ufeff / \\ufeff36.5786°N 118.2920°W'], ['2', 'Mount Williamson', 'Sierra Nevada', '14,379\\xa0ft\\\\n4383\\xa0m', '1,677\\xa0ft\\\\n511\\xa0m', '5.4\\xa0mi\\\\n8.7\\xa0km', '36°39′21″N 118°18′40″W\\ufeff / \\ufeff36.6559°N 118.3111°W'], ['3', 'White Mountain Peak', 'White Mountains', '14,252\\xa0ft\\\\n4344\\xa0m', '7,196\\xa0ft\\\\n2193\\xa0m', '67\\xa0mi\\\\n109\\xa0km', '37°38′03″N 118°15′21″W\\ufeff / \\ufeff37.6341°N 118.2557°W'], ['4', 'North Palisade', 'Sierra Nevada', '14,248\\xa0ft\\\\n4343\\xa0m', '2,894\\xa0ft\\\\n882\\xa0m', '32\\xa0mi\\\\n52\\xa0km', '37°05′39″N 118°30′52″W\\ufeff / \\ufeff37.0943°N 118.5145°W'], ['5', 'Mount Shasta', 'Cascade Range', '14,179\\xa0ft\\\\n4322\\xa0m', '9,832\\xa0ft\\\\n2997\\xa0m', '335\\xa0mi\\\\n539\\xa0km', '41°24′33″N 122°11′42″W\\ufeff / \\ufeff41.4092°N 122.1949°W'], ['6', 'Mount Humphreys', 'Sierra Nevada', '13,992\\xa0ft\\\\n4265\\xa0m', '2,563\\xa0ft\\\\n781\\xa0m', '15\\xa0mi\\\\n24\\xa0km', '37°16′14″N 118°40′23″W\\ufeff / \\ufeff37.2705°N 118.6730°W'], ['7', 'Mount Keith', 'Sierra Nevada', '13,982\\xa0ft\\\\n4262\\xa0m', '1,936\\xa0ft\\\\n590\\xa0m', '3.1\\xa0mi\\\\n5.0\\xa0km', '36°42′00″N 118°20′37″W\\ufeff / \\ufeff36.7001°N 118.3436°W'], ['8', 'Mount Darwin', 'Sierra Nevada', '13,837\\xa0ft\\\\n4218\\xa0m', '1,891\\xa0ft\\\\n576\\xa0m', '7\\xa0mi\\\\n11\\xa0km', '37°10′01″N 118°40′20″W\\ufeff / \\ufeff37.1669°N 118.6721°W'], ['9', 'Mount Kaweah', 'Sierra Nevada', '13,807\\xa0ft\\\\n4209\\xa0m', '2,027\\xa0ft\\\\n618\\xa0m', '11\\xa0mi\\\\n17\\xa0km', '36°31′34″N 118°28′43″W\\ufeff / \\ufeff36.5261°N 118.4785°W'], ['10', 'Mount Morgan', 'Sierra Nevada', '13,758\\xa0ft\\\\n4193\\xa0m', '2,648\\xa0ft\\\\n807\\xa0m', '10\\xa0mi\\\\n16\\xa0km', '37°24′19″N 118°43′58″W\\ufeff / \\ufeff37.4053°N 118.7329°W'], ['11', 'Mount Gabb', 'Sierra Nevada', '13,747\\xa0ft\\\\n4190\\xa0m', '2,601\\xa0ft\\\\n793\\xa0m', '4.3\\xa0mi\\\\n6.9\\xa0km', '37°22′37″N 118°48′09″W\\ufeff / \\ufeff37.3769°N 118.8025°W'], ['12', 'Mount Tom', 'Sierra Nevada', '13,657\\xa0ft\\\\n4163\\xa0m', '1,992\\xa0ft\\\\n607\\xa0m', '4.8\\xa0mi\\\\n7.7\\xa0km', '37°22′34″N 119°10′44″W\\ufeff / \\ufeff37.3762°N 119.1789°W'], ['13', 'Mount Dubois', 'White Mountains', '13,565\\xa0ft\\\\n4135\\xa0m', '2,339\\xa0ft\\\\n713\\xa0m', '10\\xa0mi\\\\n16\\xa0km', '37°47′00″N 118°20′36″W\\ufeff / \\ufeff37.7834°N 118.3432°W'], ['14', 'Mount Pinchot', 'Sierra Nevada', '13,500\\xa0ft\\\\n4115\\xa0m', '2,110\\xa0ft\\\\n643\\xa0m', '4.7\\xa0mi\\\\n7.6\\xa0km', '36°56′50″N 118°24′19″W\\ufeff / \\ufeff36.9473°N 118.4054°W'], ['15', 'Red Slate Mountain', 'Sierra Nevada', '13,162\\xa0ft\\\\n4012\\xa0m', '1,736\\xa0ft\\\\n529\\xa0m', '8\\xa0mi\\\\n13\\xa0km', '37°30′27″N 118°52′09″W\\ufeff / \\ufeff37.5075°N 118.8693°W'], ['16', 'Mount Ritter', 'Sierra Nevada', '13,149\\xa0ft\\\\n4008\\xa0m', '3,990\\xa0ft\\\\n1216\\xa0m', '22\\xa0mi\\\\n35\\xa0km', '37°41′21″N 119°11′59″W\\ufeff / \\ufeff37.6891°N 119.1996°W']], 'name': 'csv/204-csv/25.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Mountain Peak', 'Mountain Range', 'Elevation', 'Prominence', 'Isolation', 'Location']"
        ],
        [
         "26",
         "how many mines were in temagami?",
         "{'header': ['Mine', 'Province', 'Coordinates', 'Town', 'Dates', 'Comments'], 'rows': [['Barton Mine*', 'Ontario', '47°07′08.75″N 79°47′09.58″W\\ufeff / \\ufeff47.1190972°N 79.7859944°W', 'Temagami', '1906-1918', 'Secondary products included gold, silver, copper and bismuth.'], ['Beanland Mine', 'Ontario', '47°05′28.71″N 79°49′30.83″W\\ufeff / \\ufeff47.0913083°N 79.8252306°W', 'Temagami', '1937-1938', 'Also produced silver'], ['Big Dan Mine', 'Ontario', '47°05′28.53″N 79°46′28.95″W\\ufeff / \\ufeff47.0912583°N 79.7747083°W', 'Temagami', '1906-1907', 'Also produced silver and arsenic'], ['Copperfields Mine*', 'Ontario', '46°57′44.41″N 80°02′13.67″W\\ufeff / \\ufeff46.9623361°N 80.0371306°W', 'Temagami', '1954-1972', 'Secondary products included cobalt, gold, nickel, palladium, platinum and silver.'], ['Dome Mine', 'Ontario', '', 'Timmins', '', ''], ['Golden Giant Mine', 'Ontario', '', 'Hemlo', '1985-2006', ''], ['Hermiston-McCauley Mine', 'Ontario', '47°05′54.30″N 79°49′38.18″W\\ufeff / \\ufeff47.0984167°N 79.8272722°W', 'Temagami', '1935-1940', ''], ['Kanichee Mine*', 'Ontario', '47°06′13.07″N 79°50′38.63″W\\ufeff / \\ufeff47.1036306°N 79.8440639°W', 'Temagami', '1937-1948, 1948-1949, 1973-1976', 'Secondary products included gold, palladium, silver and platinum.'], ['Leckie Mine', 'Ontario', '47°05′36.34″N 79°47′48.68″W\\ufeff / \\ufeff47.0934278°N 79.7968556°W', 'Temagami', '~1900-1909, 1933-1937', 'Also produced arsenic, copper and silver'], ['McIntyre Mines', 'Ontario', '', '', '', ''], ['Norrie Mine*', 'Ontario', '47°06′59.59″N 79°46′27.63″W\\ufeff / \\ufeff47.1165528°N 79.7743417°W', 'Temagami', 'Prior to 1920', 'Secondary products included lead, gold, zinc and silver.'], ['Northland Pyrite Mine*', 'Ontario', '47°10′26.24″N 79°44′34.45″W\\ufeff / \\ufeff47.1739556°N 79.7429028°W', 'Temagami', '1906-1911', 'Secondary products included cobalt, copper, zinc, gold and nickel.'], ['Red Lake Mine', 'Ontario', '', 'Red Lake', '', ''], ['Temagami-Lorrain Mine', 'Ontario', '47°06′39.79″N 79°40′58.2″W\\ufeff / \\ufeff47.1110528°N 79.682833°W', 'Temagami', 'Prior to 1912', 'Also produced cobalt, arsenic, silver, nickel and copper']], 'name': 'csv/204-csv/944.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Mine', 'Province', 'Coordinates', 'Town', 'Dates', 'Comments']"
        ],
        [
         "27",
         "how many gold medals did this country win during these olympics?",
         "{'header': ['Medal', 'Name', 'Sport', 'Event', 'Date'], 'rows': [['Gold', 'Louis Chaillot, Maurice Perrin', 'Cycling', \"Men's tandem\", 'August 3'], ['Gold', 'Xavier Lesage', 'Equestrian', 'Individual dressage', 'August 10'], ['Gold', 'André Jousseaume, Xavier Lesage,\\\\nCharles Marion', 'Equestrian', 'Team dressage', 'August 10'], ['Gold', 'Georges Buchard, Philippe Cattiau,\\\\nFernand Jourdant, Jean Piot,\\\\nBernard Schmetz, Georges Tainturier', 'Fencing', \"Men's team épée\", 'August 7'], ['Gold', 'René Bondoux, René Bougnol,\\\\nPhilippe Cattiau, Edward Gardère,\\\\nRené Lemoine, Jean Piot', 'Fencing', \"Men's team foil\", 'August 1'], ['Gold', 'Jacques Lebrun', 'Sailing', 'Snowbird class', 'August 12'], ['Gold', 'Raymond Suvigny', 'Weightlifting', \"Men's 60 kg\", 'July 31'], ['Gold', 'René Duverger', 'Weightlifting', \"Men's 67.5 kg\", 'July 30'], ['Gold', 'Louis Hostin', 'Weightlifting', \"Men's 82.5 kg\", 'July 30'], ['Gold', 'Charles Pacôme', 'Wrestling', \"Men's freestyle lightweight\", 'August 3'], ['Silver', 'Louis Chaillot', 'Cycling', \"Men's sprint\", 'August 3'], ['Silver', 'Paul Chocque, Amédée Fournier,\\\\nRené Le Grèves, Henri Mouillefarine', 'Cycling', \"Men's team pursuit\", 'August 2'], ['Silver', 'Charles Marion', 'Equestrian', 'Individual dressage', 'August 10'], ['Silver', 'Georges Buchard', 'Fencing', \"Men's épée\", 'August 9'], ['Silver', 'Jean Taris', 'Swimming', \"Men's 400 m freestyle\", 'August 10'], ['Bronze', 'Paul Winter', 'Athletics', \"Men's discus throw\", 'August 3'], ['Bronze', 'Charles Rampelberg', 'Cycling', \"Men's 1000 m time trial\", 'August 1'], ['Bronze', 'Pierre Brunet, Anselme Brusa,\\\\nAndré Giriat', 'Rowing', \"Men's coxed pair\", 'August 13'], ['Bronze', 'Louis François', 'Wrestling', \"Men's Greco-Roman bantamweight\", 'August 7']], 'name': 'csv/204-csv/884.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Medal', 'Name', 'Sport', 'Event', 'Date']"
        ],
        [
         "28",
         "which schools have the largest number of shared titles?",
         "{'header': ['School', 'Location', 'Outright Titles', 'Shared Titles', 'Runners-Up', 'Total Finals', 'Last Title', 'Last Final'], 'rows': [['Methodist College Belfast', 'Belfast', '35', '2', '25', '62', '2014', '2014'], ['Royal Belfast Academical Institution', 'Belfast', '29', '4', '21', '54', '2007', '2013'], ['Campbell College', 'Belfast', '23', '4', '12', '39', '2011', '2011'], ['Coleraine Academical Institution', 'Coleraine', '9', '0', '24', '33', '1992', '1998'], ['The Royal School, Armagh', 'Armagh', '9', '0', '3', '12', '2004', '2004'], ['Portora Royal School', 'Enniskillen', '6', '1', '5', '12', '1942', '1942'], ['Bangor Grammar School', 'Bangor', '5', '0', '4', '9', '1988', '1995'], ['Ballymena Academy', 'Ballymena', '3', '0', '6', '9', '2010', '2010'], ['Rainey Endowed School', 'Magherafelt', '2', '1', '2', '5', '1982', '1982'], ['Foyle College', 'Londonderry', '2', '0', '4', '6', '1915', '1915'], ['Belfast Royal Academy', 'Belfast', '1', '3', '5', '9', '1997', '2010'], ['Regent House Grammar School', 'Newtownards', '1', '1', '2', '4', '1996', '2008'], ['Royal School Dungannon', 'Dungannon', '1', '0', '4', '5', '1907', '1975'], ['Annadale Grammar School (now Wellington College)', 'Belfast', '1', '0', '1', '2', '1958', '1978'], ['Ballyclare High School', 'Ballyclare', '1', '0', '1', '2', '1973', '2012'], [\"Belfast Boys' Model School\", 'Belfast', '1', '0', '0', '1', '1971', '1971'], ['Grosvenor High School', 'Belfast', '1', '0', '0', '1', '1983', '1983'], ['Wallace High School', 'Lisburn', '0', '0', '4', '4', 'N/A', '2007'], ['Derry Academy', 'Derry', '0', '0', '2', '2', 'N/A', '1896'], ['Dalriada School', 'Ballymoney', '0', '0', '1', '1', 'N/A', '1993'], ['Galway Grammar School', 'Galway', '0', '0', '1', '1', 'N/A', '1887'], ['Lurgan College', 'Lurgan', '0', '0', '1', '1', 'N/A', '1934'], ['Omagh Academy', 'Omagh', '0', '0', '1', '1', 'N/A', '1985'], ['Sullivan Upper School', 'Holywood', '0', '0', '1', '1', 'N/A', '2014']], 'name': 'csv/203-csv/362.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['School', 'Location', 'Outright Titles', 'Shared Titles', 'Runners-Up', 'Total Finals', 'Last Title', 'Last Final']"
        ],
        [
         "29",
         "what name comes next fairfield?",
         "{'header': ['Name', 'Date built', 'Builder', 'Works No.', 'Wheels', 'Cylinders', 'Notes', 'Withdrawn'], 'rows': [['Veteran', '1847', '?', '?', '0-6-0', 'Inside', 'arr. 1847', '?'], ['Fairfield', '1847', '?', '?', '0-6-0', 'Inside', 'arr. 1847', '?'], ['Waverley', '?', 'Henry Hughes of Loughborough', '?', '0-4-0ST', 'Outside', '-', '1889'], ['Bee', '?', '?', '?', '0-6-0T', '?', '-', '?'], ['Spider', '?', '?', '?', '0-6-0T', '?', '-', '?'], ['Gillingham', '?', 'Aveling and Porter', '?', '0-6-0TG', '?', 'arr. 1893', '1893'], ['No.1', '1880', 'Hunslet', '231', '0-6-0ST', 'Inside', 'arr. 1893', '1923'], ['No.2', '1898', 'Peckett', '696', '0-4-0ST', 'Outside', 'arr. 1904', '1923']], 'name': 'csv/204-csv/476.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Name', 'Date built', 'Builder', 'Works No.', 'Wheels', 'Cylinders', 'Notes', 'Withdrawn']"
        ],
        [
         "30",
         "which is the most recent source for the name?",
         "{'header': ['Year', 'Name', 'Source', 'Definition'], 'rows': [['c. 486 BC', 'Hidush', 'Naksh-i-Rustam', '\"Says Darius the King: By the grace of Ormazd these (are) the countries which I have acquired besides Persia. I have established my power over them. They have brought tribute to me. That which has been said to them by me they have done. They have obeyed my law. Medea... Arachotia (Harauvatish), Sattagydia (Thatagush), Gandaria (Gadára), India (Hidush)....\"'], ['c.400-300 BC', 'Hodu', 'Book of Esther', 'says \"Now it took place in the days of Ahasuerus, the Ahasuerus who reigned from Hodu(India) to Cush(Ethiopia) over 127 provinces\"'], ['c. 440 BC', 'India', 'Herodotus', '\"Eastward of India lies a tract which is entirely sand. Indeed, of all the inhabitants of Asia, concerning whom anything is known, the Indians dwell nearest to the east, and the rising of the Sun.\"'], ['c. 300 BC', 'India/Indikē', 'Megasthenes', '\"India then being four-sided in plan, the side which looks to the Orient and that to the South, the Great Sea compasseth; that towards the Arctic is divided by the mountain chain of Hēmōdus from Scythia, inhabited by that tribe of Scythians who are called Sakai; and on the fourth side, turned towards the West, the Indus marks the boundary, the biggest or nearly so of all rivers after the Nile.\"'], ['c. 140.', 'Indoi, Indou', 'Arrian', '\"The boundary of the land of India towards the north is Mount Taurus. It is not still called Taurus in this land; but Taurus begins from the sea over against Pamphylia and Lycia and Cilicia; and reaches as far as the Eastern Ocean, running right across Asia. But the mountain has different names in different places; in one, Parapamisus, in another Hemodus; elsewhere it is called Imaon, and perhaps has all sorts of other names; but the Macedonians who fought with Alexander called it Caucasus; another Caucasus, that is, not the Scythian; so that the story ran that Alexander came even to the far side of the Caucasus. The western part of India is bounded by the river Indus right down to the ocean, where the river runs out by two mouths, not joined together as are the five mouths of the Ister; but like those of the Nile, by which the Egyptian delta is formed; thus also the Indian delta is formed by the river Indus, not less than the Egyptian; and this in the Indian tongue is called Pattala. Towards the south this ocean bounds the land of India, and eastward the sea itself is the boundary. The southern part near Pattala and the mouths of the Indus were surveyed by Alexander and Macedonians, and many Greeks; as for the eastern part, Alexander did not traverse this beyond the river Hyphasis. A few historians have described the parts which are this side of the Ganges and where are the mouths of the Ganges and the city of Palimbothra, the greatest Indian city on the Ganges. (...) The Indian rivers are greater than any others in Asia; greatest are the Ganges and the Indus, whence the land gets its name; each of these is greater than the Nile of Egypt and the Scythian Ister, even were these put together; my own idea is that even the Acesines is greater than the Ister and the Nile, where the Acesines having taken in the Hydaspes, Hydraotes, and Hyphasis, runs into the Indus, so that its breadth there becomes thirty stades. Possibly also other greater rivers run through the land of India.\"'], ['320 CE or later', 'Bhāratam', 'Vishnu Purana', '\"उत्तरं यत्समुद्रस्य हिमाद्रेश्चैव दक्षिणम् ।\\\\nवर्षं तद् भारतं नाम भारती यत्र संततिः ।।\"\\\\ni.e. \"The country (varṣam) that lies north of the ocean and south of the snowy mountains is called Bhāratam; there dwell the descendants of Bharata.\"'], ['c. 590.', 'Hind', 'Istakhri', '\"As for the land of the Hind it is bounded on the East by the Persian Sea (i.e. the Indian Ocean), on the W. and S. by the countries of Islām, and on the N. by the Chinese Empire. . . . The length of the land of the Hind from the government of Mokrān, the country of Mansūra and Bodha and the rest of Sind, till thou comest to Kannūj and thence passest on to Tibet, is about 4 months, and its breadth from the Indian Ocean to the country of Kannūj about three months.\"'], ['c. 650', 'Five Indies', 'Xuanzang', '\"The circumference of 五印 (Modern Chinese: Wǔ Yìn, the Five Indies) is about 90,000 li; on three sides it is bounded by a great sea; on the north it is backed by snowy mountains. It is wide at the north and narrow at the south; its figure is that of a half-moon.\"'], ['c. 944.', 'Hind, Sind', 'Masudi', '\"For the nonce let us confine ourselves to summary notices concerning the kings of Sind and Hind. The language of Sind is different from that of Hind. . . .\"'], ['c. 1020', 'Hind', 'Al-Birūnī', '\"Hind is surrounded on the East by Chín and Máchín, on the West by Sind and Kábul, and on the South by the Sea.\"-'], ['1205', 'Hind', 'Hasan Nizāmī', '\"The whole country of Hind, from Peshawar in the north, to the Indian Ocean in the south; from Sehwan (on the west bank of the Indus) to the mountains on the east dividing from China.\"'], ['1298', 'India the Greater\\\\nIndia the Minor\\\\nMiddle India', 'Marco Polo', '\"India the Greater is that which extends from Maabar to Kesmacoran (i.e. from Coromandel to Mekran), and it contains 13 great kingdoms. . . . India the Lesser extends from the Province of Champa to Mutfili (i.e. from Cochin-China to the Kistna Delta), and contains 8 great Kingdoms. . . . Abash (Abyssinia) is a very great province, and you must know that it constitutes the Middle India.\"'], ['c. 1328.', 'India', 'Friar Jordanus', '\"What shall I say? The great- ness of this India is beyond description. But let this much suffice concerning India the Greater and the Less. Of India Tertia I will say this, that I have not indeed seen its many marvels, not having been there. . . .\"'], ['1404', 'India Minor', 'Clavijo', '\"And this same Thursday that the said Ambassadors arrived at this great River (the Oxus) they crossed to the other side. And the same day . . . came in the evening to a great city which is called Tenmit (Termez), and this used to belong to India Minor, but now belongs to the empire of Samarkand, having been conquered by Tamurbec.\"']], 'name': 'csv/202-csv/250.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Year', 'Name', 'Source', 'Definition']"
        ],
        [
         "31",
         "which province is the top consumer of wine?",
         "{'header': ['', 'Wine', 'Rank', 'Beer', 'Rank', 'Spirits', 'Rank', 'Total', 'Rank↓'], 'rows': [['Yukon', '18.3', '1', '90.6', '1', '13.8', '1', '12.7', '1'], ['Northwest Territories', '8.1', '7', '55.2', '5', '10.8', '2', '9.2', '2'], ['Alberta', '13.9', '4', '89.8', '4', '7.6', '9', '8.6', '3'], ['Newfoundland & Labrador', '6.5', '11', '93.3', '3', '7.3', '10', '8.0', '4'], ['British Columbia', '14.5', '3', '76.6', '12', '9.0', '7', '7.8', '5'], ['Ontario', '11.8', '5', '84.3', '6', '8.8', '8', '7.8', '6'], ['Quebec', '17.4', '2', '93.9', '2', '4.1', '12', '7.8', '7'], ['Prince Edward Island', '7.4', '10', '78.9', '9', '9.7', '3', '7.5', '8'], ['Nova Scotia', '8.0', '8', '79.5', '8', '9.1', '5', '7.5', '9'], ['Manitoba', '8.0', '9', '76.8', '10', '9.4', '4', '7.4', '10'], ['Saskatchewan', '5.0', '12', '76.8', '11', '9.1', '6', '7.0', '11'], ['New Brunswick', '8.4', '6', '79.8', '7', '6.8', '11', '6.7', '12'], ['Nunavut', 'Data unavailable', 'Data unavailable', 'Data unavailable', 'Data unavailable', 'Data unavailable', 'Data unavailable', 'Data unavailable', 'Data unavailable'], ['Canada', '13.1', '', '85.6', '', '7.5', '', '7.8', '']], 'name': 'csv/204-csv/533.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['', 'Wine', 'Rank', 'Beer', 'Rank', 'Spirits', 'Rank', 'Total', 'Rank↓']"
        ],
        [
         "32",
         "how long did ian armstrong serve?",
         "{'header': ['Member', 'Party', 'Term'], 'rows': [['John Ryan', 'None', '1859–1864'], ['James Martin', 'None', '1864–1869'], ['James Watson', 'None', '1869–1880'], ['Member', 'Party', 'Term'], ['James Carroll', 'Independent Protectionist', '1894–1895'], ['James Carroll', 'Protectionist', '1895–1901'], ['James Carroll', 'Progressive', '1901–1904'], ['Andrew Kelly', 'Labor', '1904–1913'], ['Thomas Brown', 'Labor', '1913–1917'], ['Ernest Buttenshaw', 'Nationalist', '1917–1920'], ['Member', 'Party', 'Term'], ['Ernest Buttenshaw', 'Country', '1927–1938'], ['Griffith Evans', 'Country', '1938–1943'], ['John Chanter', 'Labor', '1943–1947'], ['Robert Medcalf', 'Country', '1947–1950'], ['Member', 'Party', 'Term'], ['Ian Armstrong', 'National', '1981–2007']], 'name': 'csv/202-csv/76.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Member', 'Party', 'Term']"
        ],
        [
         "33",
         "how many airlines have a steady ranking?",
         "{'header': ['Rank', 'City', 'Passengers', 'Ranking', 'Airline'], 'rows': [['1', 'United States, Los Angeles', '14,749', '', 'Alaska Airlines'], ['2', 'United States, Houston', '5,465', '', 'United Express'], ['3', 'Canada, Calgary', '3,761', '', 'Air Transat, WestJet'], ['4', 'Canada, Saskatoon', '2,282', '4', ''], ['5', 'Canada, Vancouver', '2,103', '', 'Air Transat'], ['6', 'United States, Phoenix', '1,829', '1', 'US Airways'], ['7', 'Canada, Toronto', '1,202', '1', 'Air Transat, CanJet'], ['8', 'Canada, Edmonton', '110', '', ''], ['9', 'United States, Oakland', '107', '', '']], 'name': 'csv/203-csv/515.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Rank', 'City', 'Passengers', 'Ranking', 'Airline']"
        ],
        [
         "34",
         "which three artists had a single at number 1 for at least 7 weeks on the australian singles charts in 1977?",
         "{'header': ['#', 'Title', 'Artist', 'Highest pos. reached', 'weeks at No. 1'], 'rows': [['1.', '\"Don\\'t Cry for Me Argentina\"', 'Julie Covington', '1', '7'], ['2.', '\"The Way You That You Do It\"', 'Pussyfoot', '1', '7'], ['3.', '\"I Just Want to Be Your Everything\"', 'Andy Gibb', '1', '7'], ['4.', '\"That\\'s Rock and Roll\"', 'Shaun Cassidy', '2', ''], ['5.', '\"Living Next Door to Alice\"', 'Smokie', '2', ''], ['6.', '\"I Go To Rio\"', 'Peter Allen', '1', '5'], ['7.', '\"Torn Between Two Lovers\"', 'Mary McGregor', '1', '4'], ['8.', '\"Walk Right In\"', 'Dr Hook', '1', '5'], ['9.', '\"You\\'re Moving Out Today\"', 'Carole Bayer Sager', '1', '4'], ['10.', '\"If You Leave Me Now\"', 'Chicago', '1', '5 (pkd #1 in 76 & 77)'], ['11.', '\"Don\\'t Give Up on Us\"', 'David Soul', '1', '3'], ['12.', '\"Lido Shuffle\" / \"What Can I Say\"', 'Boz Scaggs', '2', ''], ['13.', '\"You and Me\"', 'Alice Cooper', '2', ''], ['14.', '\"Dance Little Lady Dance\"', 'Tina Charles', '4', ''], ['15.', '\"When I Need You\"', 'Leo Sayer', '8', ''], ['16.', '\"Don\\'t Fall in Love\"', 'Ferrets', '2', ''], ['17.', '\"I Feel Love\"', 'Donna Summer', '1', '1'], ['18.', '\"Help is on its Way\"', 'Little River Band', '1', '1'], ['19.', '\"You Gotta Get Up and Dance\"', 'Supercharge', '3', ''], ['20.', '\"Mull of Kintyre\"', 'Wings', '1', '11 (pkd #1 in 77 & 78)'], ['21.', '\"Don\\'t Leave Me This Way\"', 'Thelma Houston', '6', ''], ['22.', '\"Ain\\'t Gonna Bump No More with No Big Fat Woman\"', 'Joe Tex', '2', ''], ['23.', '\"You\\'re in My Heart\"', 'Rod Stewart', '1', '1'], ['24.', '\"Ma Baker\"', 'Boney M', '5', ''], ['25.', '\"Lucille\"', 'Kenny Rogers', '7', '']], 'name': 'csv/203-csv/197.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['#', 'Title', 'Artist', 'Highest pos. reached', 'weeks at No. 1']"
        ],
        [
         "35",
         "what car achieved the highest qual?",
         "{'header': ['Year', 'Car', 'Start', 'Qual', 'Rank', 'Finish', 'Laps', 'Led', 'Retired'], 'rows': [['1961', '98', '5', '146.080', '7', '12', '192', '27', 'Flagged'], ['1962', '98', '1', '150.370', '1', '7', '200', '120', 'Running'], ['1963', '98', '1', '151.153', '1', '1', '200', '167', 'Running'], ['1964', '98', '4', '155.099', '4', '23', '55', '7', 'Pit fire'], ['1965', '98', '5', '158.625', '5', '2', '200', '0', 'Running'], ['1966', '98', '4', '162.484', '4', '14', '87', '0', 'Wheel Bearing'], ['1967', '40', '6', '166.075', '6', '6', '196', '171', 'Bearing'], ['Totals', 'Totals', 'Totals', 'Totals', 'Totals', 'Totals', '1130', '492', '']], 'name': 'csv/203-csv/339.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Year', 'Car', 'Start', 'Qual', 'Rank', 'Finish', 'Laps', 'Led', 'Retired']"
        ],
        [
         "36",
         "what award was won previously just before the medaglia pontificia anno xiii was awarded?",
         "{'header': ['', 'Date of Award', 'Honour/Award Title', 'Reason for Award', 'Awarding Body'], 'rows': [['1', '1973', 'Lenin Peace Prize', '', 'USSR'], ['2', '1980', 'Frederic Joliot Curie Gold Medal', '', ''], ['3', '1984', \"Medaglia Pontificia (Pope's Medal) Anno VI\", '', 'The Vatican City,Italy'], ['4', '1988', 'Grant Master Order Merit: The Grant Cruz (Highest Order)', '', 'Brazil'], ['5', '1988', 'Ho Chi Minh Peace Award', '', 'Vietnam'], ['6', '1988', 'The Namibia Freedom Award', 'For his leadership role in the struggle against apartheid', 'California State University, USA'], ['7', '1988', 'Honorary Citizenship of the City of Atlanta', 'For his leadership role in the struggle for freedom, national independence and social justice', 'Atlanta, USA'], ['8', '1988', 'Recognition granted', '', 'City and County of San Francisco'], ['9', '1988', 'Recognition granted', '', 'City of Chicago'], ['10', '1988', 'Recognition granted', '', 'City of East Palo Alto'], ['11', '1990', 'Indira Gandhi Peace Prize for Disarmament and Development', 'In recognition of his outstanding contribution in leading the people of Namibia to freedom', 'India'], ['12', '1991', \"Medaglia Pontificia (Pope's Medal) Anno XIII\", '', 'The Vatican City, Italy'], ['13', '1991', 'Order of José Marti', '', 'Cuba'], ['14', '1991', 'Ordre du Merite Congo', '', 'Republic of Congo'], ['15', '1992', 'Chief of Golden Heart', '', 'Kenya'], ['16', '1992', 'Order of the National Flag (First Class)', '', \"Democratic People's Republic of Korea\"], ['17', '1994', '\"Grand Cordon\" Decoration', '', 'Tunisia'], ['18', '1995', 'Grand Master of the Order of Welwitschia', '', 'Namibia'], ['19', '1995', 'Order of Liberty (Highest Cross)', '', 'Portugal'], ['20', '1995', 'Africa Prize for Leadership for the Sustainable End of Hunger', '', 'The Hunger Project'], ['21', '1996', 'Order of Good Hope (Gold)', '', 'South Africa'], ['22', '2002', 'Order of Friendship Award', '', 'Vietnam'], ['23', '2003', 'O.B.F.F.S.', '', 'Romania'], ['24', '2003', 'Fellowship Award of the Institute of Governance and Social Research', 'In recognition of his contribution to the liberation of his country, the establishment of Democratic foundation, peace and Political stability in Namibia, and the enhancement of the dignity of the Black Man', 'Institute of Governance and Social Research, Nigeria'], ['25', '2004', 'Companion of the Order of the Star of Ghana (Ghana National Highest Award)', 'As an expression of respect and admiration of the Government and people of Ghana', 'Ghana'], ['26', '2004', 'Founding President of the Republic of Namibia and Father of the Namibian Nation', 'In recognition of his dedication to his selfless sacrifice to the national liberation struggle and nation building', 'Namibian Parliament'], ['27', '2004', 'Lifetime Conservation Award', '', 'Cheetah Conservation Fund (Nujoma is the international patron of this organisation since 1991)'], ['28', '2008', 'International KIM IL Sung Prize Certificate', '', 'India'], ['29', '2010', 'Sir Seretse Khama SADC Meda', '', 'SADC']], 'name': 'csv/203-csv/769.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['', 'Date of Award', 'Honour/Award Title', 'Reason for Award', 'Awarding Body']"
        ],
        [
         "37",
         "when was the last super chinese game released?",
         "{'header': ['Japanese Title', 'Western Title', 'Regions', 'Release', 'Platform(s)', 'Genre'], 'rows': [['Chinese Hero', '-', 'JP', '1984', 'Arcade', 'Action'], ['Super Chinese', 'Kung-Fu Heroes', 'JP, NA', '1986', 'FC/NES', 'Action'], ['Super Chinese 2', 'Little Ninja Brothers', 'JP, NA', '1989', 'FC/NES', 'Role-Playing'], ['Super Chinese 3', '-', 'JP', '1991', 'FC', 'Role-Playing'], ['Super Chinese Land', 'Ninja Boy', 'JP, NA', '1990', 'GB', 'Action'], ['Super Chinese Land 2', 'Ninja Boy 2', 'JP, NA', '1990', 'GB', 'Role-Playing'], ['Super Chinese Land 3', '-', 'JP', '1995', 'GB', 'Role-Playing'], ['Super Chinese World', 'Super Ninja Boy', 'JP, NA', '1991', 'SFC/SNES', 'Role-Playing'], ['Super Chinese World 2', '-', 'JP', '1993', 'SFC', 'Role-Playing'], ['Super Chinese World 3', '-', 'JP', '1995', 'SFC', 'Role-Playing'], ['Super Chinese Fighter', '-', 'JP', '1995', 'SFC', 'Fighting'], ['Super Chinese Fighter GB', '-', 'JP', '1996', 'GB', 'Fighting'], ['Super Chinese Fighter EX', '-', 'JP', '1999', 'GBC', 'Fighting']], 'name': 'csv/203-csv/55.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Japanese Title', 'Western Title', 'Regions', 'Release', 'Platform(s)', 'Genre']"
        ],
        [
         "38",
         "what year had a total of 2 titles released?",
         "{'header': ['Title', 'Year', 'Platforms', 'Developer', 'Publisher', 'Notes'], 'rows': [[\"American McGee's Grimm\", '2008', 'PC', 'Spicy Horse', 'GameTap', 'Episodic McGee takes on various Grimm tales.'], ['DexIQ', '2009', 'iPad, iPhone, iPod', 'Spicy Pony', '', 'Puzzle game'], ['American McGee Presents Akaneiro', '2010', 'iPad', 'Spicy Pony', '', 'Little Red Riding Hood in Japan'], [\"American McGee's Crooked House\", '2010', 'iPad, iPhone, iPod', 'Spicy Pony', '', 'Puzzle game'], ['Alice: Madness Returns', '2011', 'PlayStation 3, Xbox 360, PC', 'Spicy Horse', 'Electronic Arts', \"Sequel to American McGee's Alice\"], ['BigHead Bash', '2012', 'TBA', 'Spicy Horse', 'TBA', 'Side scrolling/battle multiplayer. (Unreleased)'], ['Crazy Fairies', '2012', 'Mobile, Facebook', 'Spicy Horse', 'TBA', 'Currently in the Closed Beta Stage. (Unreleased)'], ['Akaneiro: Demon Hunters', '2013', 'Browsers, Tegra-powered tablets', 'Spicy Horse', 'Spicy Horse', 'A Japanese/McGee take on Little Red Riding Hood.']], 'name': 'csv/203-csv/836.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Title', 'Year', 'Platforms', 'Developer', 'Publisher', 'Notes']"
        ],
        [
         "39",
         "what year has no place indicated?",
         "{'header': ['Season', 'Tier', 'Division', 'Place'], 'rows': [['1981/82', '4', '3ª', '17th'], ['1982/83', '5', 'Regional', '—'], ['1983/84', '4', '3ª', '1st'], ['1984/85', '4', '3ª', '2nd'], ['1985/86', '4', '3ª', '1st'], ['1986/87', '3', '2ªB', '10th'], ['1987/88', '3', '2ªB', '1st'], ['1988/89', '2', '2ª', '18th'], ['1989/90', '3', '2ªB', '7th'], ['1990/91', '3', '2ªB', '8th'], ['1991/92', '3', '2ªB', '20th'], ['1992/93', '4', '3ª', '14th'], ['1993/94', '4', '3ª', '19th'], ['1994/95', '5', 'Reg. Pref.', '9th'], ['1995/96', '5', 'Reg. Pref.', '4th'], ['1996/97', '5', 'Reg. Pref.', '1st'], ['1997/98', '5', 'Reg. Pref.', '2nd']], 'name': 'csv/203-csv/231.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Season', 'Tier', 'Division', 'Place']"
        ],
        [
         "40",
         "what is the number of points scored on 6 february 1922?",
         "{'header': ['Tie no', 'Home team', 'Score', 'Away team', 'Date'], 'rows': [['1', 'Liverpool', '0–1', 'West Bromwich Albion', '28 January 1922'], ['2', 'Preston North End', '3–1', 'Newcastle United', '28 January 1922'], ['3', 'Southampton', '1–1', 'Cardiff City', '28 January 1922'], ['Replay', 'Cardiff City', '2–0', 'Southampton', '1 February 1922'], ['4', 'Leicester City', '2–0', 'Fulham', '28 January 1922'], ['5', 'Nottingham Forest', '3–0', 'Hull City', '28 January 1922'], ['6', 'Aston Villa', '1–0', 'Luton Town', '28 January 1922'], ['7', 'Bolton Wanderers', '1–3', 'Manchester City', '28 January 1922'], ['8', 'Swindon Town', '0–1', 'Blackburn Rovers', '28 January 1922'], ['9', 'Tottenham Hotspur', '1–0', 'Watford', '28 January 1922'], ['10', 'Barnsley', '3–1', 'Oldham Athletic', '28 January 1922'], ['11', 'Northampton Town', '2–2', 'Stoke', '28 January 1922'], ['Replay', 'Stoke', '3–0', 'Northampton Town', '1 February 1922'], ['12', 'Brighton & Hove Albion', '0–0', 'Huddersfield Town', '28 January 1922'], ['Replay', 'Huddersfield Town', '2–0', 'Brighton & Hove Albion', '1 February 1922'], ['13', 'Bradford City', '1–1', 'Notts County', '28 January 1922'], ['Replay', 'Notts County', '0–0', 'Bradford City', '1 February 1922'], ['Replay', 'Notts County', '1–0', 'Bradford City', '6 February 1922'], ['14', 'Crystal Palace', '0–0', 'Millwall', '28 January 1922'], ['Replay', 'Millwall', '2–0', 'Crystal Palace', '1 February 1922'], ['15', 'Southend United', '0–1', 'Swansea Town', '28 January 1922'], ['16', 'Bradford Park Avenue', '2–3', 'Arsenal', '28 January 1922']], 'name': 'csv/204-csv/267.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Tie no', 'Home team', 'Score', 'Away team', 'Date']"
        ],
        [
         "41",
         "which year had the largest agricultural volume?",
         "{'header': ['IME Exchange (Including spot, credit and forward transactions)', '2007/08', '2008/09', '2009/10', '2010/11', '2011/12'], 'rows': [['Agricultural - Volume (thousand tons)', '273.0', '173.5', '175.2', '1,633.9', '550.0'], ['Agricultural - Value (billion rials)', '772.6', '3,729.7', '484.8', '3,729.0', '3,793.0'], ['Manufacturing and Metal - Volume (thousand tons)', '6,443.8', '6,679.7', '7,438.5', '8,694.0', '11,685.0'], ['Manufacturing and Metal - Value (billion rials)', '58,044.2', '62,120.6', '53,842.0', '75,235.5', '102,356.0'], ['Oil and Petrochemical - Volume (thousand tons)', '89.7', '4,339.2', '7,052.9', '6,662.6', '8,117.0'], ['Oil and Petrochemical - Value (billion rials)', '352.7', '19,921.0', '36,450.7', '41,478.0', '64,370.0'], ['Grand Total - Volume (thousand tons)', '6,806.5', '11,192.4', '14,666.6', '16,990.5', '20,351.0'], ['Grand Total - Value (billion rials)', '59,169.4', '82,685.3', '90,777.5', '120,443.2', '170,519.0']], 'name': 'csv/204-csv/666.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['IME Exchange (Including spot, credit and forward transactions)', '2007/08', '2008/09', '2009/10', '2010/11', '2011/12']"
        ],
        [
         "42",
         "which illustrator was responsible for the last award winner?",
         "{'header': ['Year', 'Author', 'Illustrator', 'Title', 'Publisher'], 'rows': [['1982', 'Angela Carter\\\\n(ed. and translator)', 'Michael Foreman', 'Sleeping Beauty and other favourite fairy tales', 'V. Gollancz'], ['1983', 'Anthony Browne', 'Browne', 'Gorilla', 'Julia MacRae'], ['1984', 'John Burningham', 'Burningham', 'Granpa', 'J. Cape'], ['1985', 'Ted Hughes (1968)', 'Andrew Davidson', 'The Iron Man', 'Faber'], ['1986', 'Allan Ahlberg', 'Janet Ahlberg', 'The Jolly Postman', 'Heinemann'], ['1987', 'Charles Causley', 'Charles Keeping', 'Jack the Treacle Eater', 'Macmillan'], ['1988', 'Lewis Carroll (1865)', 'Anthony Browne', \"Alice's Adventures in Wonderland\", 'Julia MacRae'], ['1989', 'Martin Waddell', 'Barbara Firth', 'The Park in the Dark', 'Walker'], ['1990', 'Quentin Blake', 'Blake', 'All Join In', 'J. Cape'], ['1991', 'Colin McNaughton', 'McNaughton', \"Have You Seen who's just moved in next door to us?\", 'Walker'], ['1992', 'Raymond Briggs', 'Briggs', 'The Man', 'Julia MacRae'], ['1993', 'Karen Wallace', 'Mike Bostock', 'Think of an Eel', 'Walker'], ['1994', 'Trish Cooke', 'Helen Oxenbury', 'So Much', 'Walker'], ['1995', 'Kathy Henderson', 'Patrick Benson', 'The Little Boat', 'Walker'], ['1996', 'Babette Cole', 'Cole', 'Drop Dead', 'J. Cape'], ['1997', 'William Mayne', 'Jonathan Heale', 'Lady Muck', 'Heinemann'], ['1998', 'Anthony Browne', 'Browne', 'Voices in the Park', 'Doubleday'], ['1999', 'Lewis Carroll (1865)', 'Helen Oxenbury', \"Alice's Adventures in Wonderland\", 'Walker']], 'name': 'csv/203-csv/788.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Year', 'Author', 'Illustrator', 'Title', 'Publisher']"
        ],
        [
         "43",
         "what is the number of buildings under 200 ft?",
         "{'header': ['Rank', 'Name', 'Height\\\\nft / m', 'Floors', 'Year', 'Notes'], 'rows': [['1', 'Rhodes State Office Tower', '629 / 192', '41', '1973', 'Has been the tallest building in Columbus and the tallest mid-block skyscraper in Ohio since 1973. Tallest building constructed in Columbus in the 1970s.'], ['2', 'LeVeque Tower', '555 / 169', '47', '1927', 'Tallest building constructed in Columbus in the 1920s.'], ['3', 'William Green Building', '530 / 162', '33', '1990', 'Tallest building constructed in Columbus in the 1990s.'], ['4', 'Huntington Center', '512 / 156', '37', '1984', 'Tallest building constructed in Columbus in the 1980s.'], ['5', 'Vern Riffe State Office Tower', '503 / 153', '32', '1988', ''], ['6', 'One Nationwide Plaza', '485 / 148', '40', '1976', ''], ['7', 'Franklin County Courthouse', '464 / 141', '27', '1991', ''], ['8', 'AEP Building', '456 / 139', '31', '1983', ''], ['9', 'Borden Building', '438 / 134', '34', '1974', ''], ['10', 'Three Nationwide Plaza', '408 / 124', '27', '1989', ''], ['11', 'One Columbus Center', '366 / 112', '26', '1987', ''], ['12', 'Columbus Center', '357 / 109', '25', '1964', 'Tallest building constructed in Columbus in the 1960s. Was built as the Bank One Tower.'], ['13', 'Capitol Square', '350 / 107', '26', '1984', ''], ['14', 'Continental Center', '348 / 106', '26', '1973', ''], ['15', 'PNC Bank Building', '317 / 97', '25', '1977', ''], ['16', 'Miranova Condominiums', '314 / 96', '26', '2001', 'Tallest residential building in the state of Ohio. Tallest building built in the 2000s.'], ['17', 'Fifth Third Center', '302 / 92', '25', '1998', ''], ['18', 'Motorists Mutual Building', '286 / 87', '21', '1973', ''], ['19', 'Midland Building', '280 / 85', '21', '1970', ''], ['20', 'The Condominiums at North Bank Park', '267 / 81', '20', '2007', ''], ['21=', 'Lincoln Tower Dormitory', '260 / 79', '26', '1967', ''], ['21=', 'Morrill Tower Dormitory', '260 / 79', '26', '1967', ''], ['23', 'Hyatt Regency Columbus', '256 / 78', '20', '1980', ''], ['24', 'Key Bank Building', '253 / 77', '20', '1963', ''], ['25', \"Adam's Mark Hotel\", '243 / 74', '16', '1961', ''], ['26', 'Town Center', '226 / 69', '17', '1974', ''], ['27', '8 East Broad Street', '212 / 64.6', '17', '1906', ''], ['28', 'Huntington Building', '202 / 59.4', '13', '1926', ''], ['29', 'Ohio Judicial Center', '200 / 57.9', '14', '1933', ''], ['30', '16 East Broad Street', '180 / 64.4', '13', '1900', '']], 'name': 'csv/203-csv/837.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Name', 'Height\\\\nft / m', 'Floors', 'Year', 'Notes']"
        ],
        [
         "44",
         "total number of players whose home town was in north carolina (nc)",
         "{'header': ['Name', '#', 'Position', 'Height', 'Weight', 'Year', 'Home Town', 'High School'], 'rows': [['Harrison Barnes', '40', 'Forward', '6–8', '210', 'Freshman', 'Ames, IA', 'Ames'], ['Daniel Bolick', '3', 'Guard', '5–10', '175', 'Senior', 'Carrboro, NC', 'Chapel Hill'], ['Reggie Bullock', '35', 'Guard', '6–7', '190', 'Freshman', 'Kinston, NC', 'Kinston'], ['Stewart Cooper', '15', 'Forward', '6–5', '205', 'Junior', 'Winston-Salem, NC', 'Forsyth County Day'], ['Patrick Crouch', '30', 'Guard', '5–11', '175', 'Junior', 'Asheville, NC', 'T.C. Roberson'], ['Larry Drew II*', '11', 'Guard', '6–2', '180', 'Junior', 'Encino, CA', 'Woodland Hills Taft'], ['David Dupont', '22', 'Forward', '6–5', '195', 'Junior', 'Greensboro, NC', 'Grimsley'], ['Van Hatchell', '13', 'Forward', '6–4', '185', 'Senior', 'Chapel Hill, NC', 'Cresset Christian'], ['John Henson', '31', 'Forward', '6–10', '210', 'Sophomore', 'Tampa, FL', 'Sickles'], ['D.J. Johnston', '32', 'Forward', '6–4', '195', 'Junior', 'Lower Gwynedd, PA', 'Germantown'], ['Justin Knox', '25', 'Forward', '6–9', '240', 'Graduate', 'Tuscaloosa, AL', 'Central'], ['Kendall Marshall', '5', 'Guard', '6–3', '186', 'Freshman', 'Dumfries, VA', \"Bishop O'Connell\"], ['Leslie McDonald', '15', 'Guard', '6–4', '215', 'Sophomore', 'Memphis, TN', 'Briarcrest Christian'], ['Dexter Strickland', '1', 'Guard', '6–3', '180', 'Sophomore', 'Rahway, NJ', 'St. Patrick'], ['Justin Watts', '24', 'Guard', '6–4', '210', 'Junior', 'Durham, NC', 'Jordan'], ['Tyler Zeller', '44', 'Forward', '7–0', '250', 'Junior', 'Washington, IN', 'Washington']], 'name': 'csv/204-csv/526.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Name', '#', 'Position', 'Height', 'Weight', 'Year', 'Home Town', 'High School']"
        ],
        [
         "45",
         "is the united stated or scotland better?",
         "{'header': ['Country', 'Masters', 'U.S. Open', 'The Open', 'PGA', 'Total'], 'rows': [['United States', '57', '80', '42', '79', '258'], ['Scotland', '1', '12', '41', '0', '54'], ['England', '3', '8', '22', '2', '35'], ['South Africa', '5', '5', '10', '2', '22'], ['Australia', '1', '2', '9', '4', '16'], ['Jersey', '0', '2', '7', '0', '9'], ['Spain', '4', '0', '3', '0', '7'], ['Northern Ireland', '0', '2', '2', '1', '5'], ['Argentina', '1', '1', '1', '0', '3'], ['Fiji', '1', '0', '0', '2', '3'], ['Germany', '2', '0', '0', '1', '3'], ['Ireland', '0', '0', '2', '1', '3'], ['Zimbabwe', '0', '0', '1', '2', '3'], ['New Zealand', '0', '1', '1', '0', '2'], ['Canada', '1', '0', '0', '0', '1'], ['France', '0', '0', '1', '0', '1'], ['South Korea', '0', '0', '0', '1', '1'], ['Wales', '1', '0', '0', '0', '1']], 'name': 'csv/204-csv/396.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Country', 'Masters', 'U.S. Open', 'The Open', 'PGA', 'Total']"
        ],
        [
         "46",
         "how many ships were launched in the year 1944?",
         "{'header': ['Name', 'Pennant', 'Builder', 'Launched', 'Original name', 'Fate'], 'rows': [['Wave Baron', 'A242', 'Furness Shipbuilding Company', '19 February 1946', 'Empire Flodden', 'Scrapped in 1972'], ['Wave Chief', 'A265', 'Harland and Wolff', '30 August 1946', 'Empire Edgehill', 'Scrapped in 1974'], ['Wave Commander', 'A244', 'Furness Shipbuilding Company', '21 April 1944', 'Empire Paladin', 'Scrapped in 1959'], ['Wave Conqueror', 'A245', 'Furness Shipbuilding Company', '27 November 1943', 'Empire Law', 'Scrapped in 1960'], ['Wave Duke', 'A246', 'Sir J. Laing & Sons Ltd', '16 November 1944', 'Empire Mars', 'Scrapped in 1969'], ['Wave Emperor', 'A100', 'Furness Shipbuilding Company', '16 October 1944', '', 'Scrapped in 1966'], ['Wave Governor', 'A247', 'Furness Shipbuilding Company', '30 November 1944', '', 'Scrapped in 1960'], ['Wave King', 'A182', 'Harland and Wolff', '21 July 1944', '', 'Scrapped in 1966'], ['Wave Knight', 'A249', 'Sir J. Laing & Sons Ltd', '22 October 1945', 'Empire Naseby', 'Scrapped in 1964'], ['Wave Laird', 'A119', 'Sir J. Laing & Sons Ltd', '3 April 1946', 'Empire Dunbar', 'Scrapped in 1970'], ['Wave Liberator', 'A248', 'Furness Shipbuilding Company', '9 February 1944', 'Empire Milner', 'Scrapped in 1959'], ['Wave Master', 'A193', 'Sir J. Laing & Sons Ltd', '20 May 1944', 'Empire Salisbury', 'Scrapped in 1963'], ['Wave Monarch', 'A264', 'Harland and Wolff', '6 July 1944', '', 'Sold as oil hulk in 1960'], ['Wave Premier', 'A129', 'Furness Shipbuilding Company', '27 June 1946', '', 'Scrapped in 1960'], ['Wave Prince', 'A207', 'Sir J. Laing & Sons Ltd', '27 July 1945', 'Empire Herald', 'Scrapped in 1971'], ['Wave Protector', 'A215', 'Furness Shipbuilding Company', '20 July 1944', 'Empire Protector', 'Scrapped in 1963'], ['Wave Regent', 'A210', 'Furness Shipbuilding Company', '29 March 1945', '', 'Scrapped in 1960'], ['Wave Ruler', 'A212', 'Furness Shipbuilding Company', '17 January 1946', 'Empire Evesham', 'Scrapped in 1977'], ['Wave Sovereign', 'A211', 'Furness Shipbuilding Company', '20 November 1945', '', 'Scrapped in 1966'], ['Wave Victor', 'A220', 'Furness Shipbuilding Company', '30 September 1943', 'Empire Bounty', 'Chartered to Air Ministry in 1960']], 'name': 'csv/203-csv/313.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Name', 'Pennant', 'Builder', 'Launched', 'Original name', 'Fate']"
        ],
        [
         "47",
         "what is the total number of gold medals won by jamaica?",
         "{'header': ['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total'], 'rows': [['1', 'United States', '5', '6', '5', '16'], ['2', 'Jamaica', '4', '1', '1', '6'], ['3', 'Netherlands', '2', '0', '0', '2'], ['4', 'Bahamas', '1', '1', '0', '2'], ['5', 'Ukraine', '1', '0', '1', '2'], ['6', 'East Germany', '1', '0', '0', '1'], ['', 'Greece', '1', '0', '0', '1'], ['', 'Soviet Union', '1', '0', '0', '1'], ['9', 'Ivory Coast', '0', '2', '0', '2'], ['', 'United Kingdom', '0', '2', '0', '2'], ['11', 'Belgium', '0', '1', '1', '2'], ['12', 'Bulgaria', '0', '1', '0', '1'], ['', 'Russia', '0', '1', '0', '1'], ['', 'Germany', '0', '1', '0', '1'], ['15', 'Canada', '0', '0', '2', '2'], ['', 'France', '0', '0', '2', '2'], ['17', 'Belarus', '0', '0', '1', '1'], ['', 'Cuba', '0', '0', '1', '1'], ['', 'Gabon', '0', '0', '1', '1'], ['', 'British Virgin Islands', '0', '0', '1', '1'], ['Total', 'Total', '16', '16', '16', '48']], 'name': 'csv/204-csv/595.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total']"
        ],
        [
         "48",
         "what number of mainlands have populations under 100,000?",
         "{'header': ['MAINLAND', 'Area\\\\n(sq miles)', 'Area\\\\n(km²)', 'Population\\\\n(2011)', 'Density\\\\n(per km²)'], 'rows': [['Aberdeen City', '70', '182', '222,800', '1224'], ['Aberdeenshire', '2,439', '6,317', '253,000', '40'], ['Angus', '843', '2,184', '116,000', '53'], ['Argyll and Bute', '2,712', '7,023', '88,200', '13'], ['Clackmannanshire', '61', '158', '51,400', '325'], ['Dumfries and Galloway', '2,489', '6,446', '151,300', '23'], ['Dundee City', '21', '55', '147,300', '2678'], ['East Ayrshire', '492', '1,275', '122,700', '96'], ['East Dunbartonshire', '68', '176', '105,000', '597'], ['East Lothian', '257', '666', '99,700', '150'], ['East Renfrewshire', '65', '168', '90,600', '539'], ['City of Edinburgh', '100', '260', '476,600', '1833'], ['Falkirk', '113', '293', '156,000', '532'], ['Fife', '517', '1,340', '365,200', '273'], ['Glasgow City', '68', '175', '593,200', '3390'], ['Highland', '10,085', '26,119', '232,100', '9'], ['Inverclyde', '64', '167', '81,500', '488'], ['Midlothian', '135', '350', '83,200', '238'], ['Moray', '864', '2,237', '93,300', '42'], ['North Ayrshire', '343', '888', '138,200', '156'], ['North Lanarkshire', '184', '476', '337,800', '710'], ['Perth and Kinross', '2,083', '5,395', '146,700', '27'], ['Renfrewshire', '102', '263', '174,900', '665'], ['Scottish Borders', '1,825', '4,727', '113,900', '24'], ['South Ayrshire', '475', '1,230', '112,800', '92'], ['South Lanarkshire', '686', '1,778', '313,800', '176'], ['Stirling', '866', '2,243', '90,200', '40'], ['West Dunbartonshire', '68', '176', '90,700', '515'], ['West Lothian', '165', '427', '175,100', '410'], ['TOTAL MAINLAND', '28,260', '73,193', '5,223,100', '71'], ['ISLANDS', '', '', '', ''], ['Na h-Eileanan Siar', '1,185', '3,070', '27,700', '8'], ['Orkney Islands', '396', '1,025', '21,400', '21'], ['Shetland Islands', '568', '1,471', '23,200', '15'], ['TOTAL ISLANDS', '2,149', '5,566', '72,300', '13'], ['TOTAL SCOTLAND', '30,409', '78,759', '5,295,400', '67']], 'name': 'csv/203-csv/401.tsv'}",
         "Lookup",
         "wikitq",
         "0",
         "['MAINLAND', 'Area\\\\n(sq miles)', 'Area\\\\n(km²)', 'Population\\\\n(2011)', 'Density\\\\n(per km²)']"
        ],
        [
         "49",
         "how many historic sites are listed in coldwater?",
         "{'header': ['Name', 'Location', 'City', 'Listing date'], 'rows': [['Branch County Courthouse Informational Site', '31 Division Street', 'Coldwater', 'March 16, 1989'], ['Bronson Public Library', '207 Matteson Street', 'Bronson', 'September 28, 2000'], ['Chicago Road Informational Designation', 'US-12 and Prairie River Road (Park 1.5 miles west of Bronson)', 'Bronson Township', 'September 17, 1957'], ['City of Coldwater Informational Designation', 'City Park at intersection of US-12 and US-27', 'Coldwater', 'April 14, 1961'], ['Edwin R. Clarke Library (Michigan Library Association)', '12 East Chicago Street, between Division and Hudson streets', 'Coldwater', 'March 9, 1966'], ['Dr. Hawley Harvey Crippen Home Site Informational Designation', '66 North Monroe Street', 'Coldwater', 'August 21, 1987'], ['East Chicago Street Historic District†', 'Chicago Street from Wright to Division streets, including the four parks at Division', 'Coldwater', 'July 26, 1974'], ['First Presbyterian Church†', '52 Marshall Street, NE corner of Marshall and Church streets', 'Coldwater', 'June 15, 1979'], ['Abram C. Fisk House†', '867 East Chicago Street', 'Coldwater', 'June 15, 1979'], ['William P. Hurd House', '601 North Broadway', 'Union City', 'July 17, 1981'], ['Lanphere-Pratt House', '90 Division Street', 'Coldwater', 'February 23, 1978'], ['Henry A. Locke House', '140 East Division Street', 'Sherwood', 'March 19, 1980'], ['Governor Cyrus Gray Luce Homesite Informational Site', 'Northeast corner of Division and East Washington streets', 'Coldwater', 'August 15, 1975'], ['Methodist Episcopal Church', '126 Marshall Road', 'Coldwater', 'April 17, 1997'], ['General John G. Parkhurst House', '55 North Clay Street', 'Coldwater', 'June 15, 1979'], ['Harriet Quimby Informational Designation', 'Branch County Memorial Airport', 'Coldwater', 'January 21, 1988'], ['Quincy Township Public Library', '11 North Main Street, just north of US-12', 'Quincy', 'April 25, 1988'], ['State Public School at Coldwater', '620 Marshall Road', 'Coldwater', 'May 13, 1981'], ['Tibbits Opera House', '14 South Hanchett Street', 'Coldwater', 'December 11, 1970'], ['Union City Iron Furnace', 'M-60 near Waterworks Road', 'Union Township', 'February 14, 1963'], ['Union City Methodist Episcopal Church', '200 Ellen Street', 'Union City', 'September 19, 1991'], ['Lucius M. Wing House†', '27 South Jefferson Street, NE corner of S. Jefferson and East Pearl Street', 'Coldwater', 'October 17, 1974'], ['John D. Zimmerman House', '119 East High Street', 'Union City', 'September 21, 1983']], 'name': 'csv/204-csv/423.tsv'}",
         "Aggregation",
         "wikitq",
         "1",
         "['Name', 'Location', 'City', 'Listing date']"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 7618
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>table</th>\n",
       "      <th>annotation</th>\n",
       "      <th>source</th>\n",
       "      <th>annotation_num</th>\n",
       "      <th>header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which team won previous to crettyard?</td>\n",
       "      <td>{'header': ['Team', 'County', 'Wins', 'Years won'], 'rows': [['Greystones', 'Wicklow', '1', '2011'], ['Ballymore Eustace', 'Kildare', '1', '2010'], ['Maynooth', 'Kildare', '1', '2009'], ['Ballyroan Abbey', 'Laois', '1', '2008'], ['Fingal Ravens', 'Dublin', '1', '2007'], ['Confey', 'Kildare', '1', '2006'], ['Crettyard', 'Laois', '1', '2005'], ['Wolfe Tones', 'Meath', '1', '2004'], ['Dundalk Gaels', 'Louth', '1', '2003']], 'name': 'csv/204-csv/772.tsv'}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikitq</td>\n",
       "      <td>0</td>\n",
       "      <td>[Team, County, Wins, Years won]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how many more passengers flew to los angeles than to saskatoon from manzanillo airport in 2013?</td>\n",
       "      <td>{'header': ['Rank', 'City', 'Passengers', 'Ranking', 'Airline'], 'rows': [['1', 'United States, Los Angeles', '14,749', '', 'Alaska Airlines'], ['2', 'United States, Houston', '5,465', '', 'United Express'], ['3', 'Canada, Calgary', '3,761', '', 'Air Transat, WestJet'], ['4', 'Canada, Saskatoon', '2,282', '4', ''], ['5', 'Canada, Vancouver', '2,103', '', 'Air Transat'], ['6', 'United States, Phoenix', '1,829', '1', 'US Airways'], ['7', 'Canada, Toronto', '1,202', '1', 'Air Transat, CanJet'], ['8', 'Canada, Edmonton', '110', '', ''], ['9', 'United States, Oakland', '107', '', '']], 'name': 'csv/203-csv/515.tsv'}</td>\n",
       "      <td>Aggregation</td>\n",
       "      <td>wikitq</td>\n",
       "      <td>1</td>\n",
       "      <td>[Rank, City, Passengers, Ranking, Airline]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>after winning on four credits with a full house, what is your payout?</td>\n",
       "      <td>{'header': ['Hand', '1 credit', '2 credits', '3 credits', '4 credits', '5 credits'], 'rows': [['Royal flush', '250', '500', '750', '1000', '4000*'], ['Straight flush', '60', '120', '180', '240', '400'], ['Four aces', '400', '800', '1200', '1600', '2000'], ['Four of a kind, 2-4', '100', '200', '300', '400', '500'], ['Four of a kind, 5-K', '50', '100', '150', '200', '250'], ['Full house', '8', '16', '24', '32', '40'], ['Flush', '5', '10', '15', '20', '25'], ['Straight', '4', '8', '12', '16', '20'], ['Three of a kind', '3', '6', '9', '12', '15'], ['Two pair', '1', '2', '3', '4', '5'], ['Jacks or better', '1', '2', '3', '4', '5'], ['Theoretical return', '98.68%', '98.68%', '98.68%', '98.68%', '99.92%*']], 'name': 'csv/203-csv/564.tsv'}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikitq</td>\n",
       "      <td>0</td>\n",
       "      <td>[Hand, 1 credit, 2 credits, 3 credits, 4 credits, 5 credits]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>which players played the same position as ardo kreek?</td>\n",
       "      <td>{'header': ['No.', 'Player', 'Birth Date', 'Weight', 'Height', 'Position', 'Current Club'], 'rows': [['4', 'Ardo Kreek', 'August 7, 1986 (age 27)', '96', '203', 'Middle blocker', 'Paris Volley'], ['5', 'Kert Toobal', 'June 3, 1979 (age 35)', '78', '189', 'Setter', 'Sivas 4 Eylül'], ['6', 'Martti Juhkami', 'June 6, 1988 (age 26)', '96', '196', 'Spiker', 'TV Bühl'], ['7', 'Argo Meresaar', 'January 13, 1980 (age 34)', '107', '206', 'Opposite', 'Bigbank Tartu'], ['8', 'Kusti Nõlvak', 'November 6, 1991 (age 22)', '81', '186', 'Setter', 'TTÜ VK'], ['9', 'Robert Täht', 'August 15, 1993 (age 20)', '80', '190', 'Spiker', 'Bigbank Tartu'], ['11', 'Oliver Venno', 'May 23, 1990 (age 24)', '105', '210', 'Opposite', 'Rennes Volley 35'], ['14', 'Rait Rikberg', 'August 30, 1982 (age 31)', '80', '174', 'Libero', 'Bigbank Tartu'], ['16', 'Edgar Järvekülg', 'June 12, 1988 (age 26)', '77', '186', 'Libero', 'Pärnu VK'], ['17', 'Siim Ennemuist', 'December 5, 1989 (age 24)', '89', '196', 'Middle blocker', 'TTÜ VK'], ['18', 'Jaanus Nõmmsalu', 'January 19, 1981 (age 33)', '94', '200', 'Spiker', 'TTÜ VK'], ['19', 'Andri Aganits', 'September 7, 1993 (age 20)', '99', '207', 'Middle Blocker', 'TV Bühl']], 'name': 'csv/203-csv/116.tsv'}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikitq</td>\n",
       "      <td>0</td>\n",
       "      <td>[No., Player, Birth Date, Weight, Height, Position, Current Club]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what was the venue when he placed first?</td>\n",
       "      <td>{'header': ['Year', 'Competition', 'Venue', 'Position', 'Notes'], 'rows': [['1996', 'World Junior Championships', 'Sydney, Australia', '15th (q)', '7.43 m'], ['1996', 'Asian Junior Championships', 'New Delhi, India', '1st', '7.68 m'], ['1999', 'World Championships', 'Seville, Spain', '6th', '8.01 m'], ['2001', 'East Asian Games', 'Osaka, Japan', '3rd', '7.77 m'], ['2002', 'Asian Championships', 'Colombo, Sri Lanka', '3rd', '7.91 m (w)'], ['2002', 'Asian Games', 'Busan, South Korea', '4th', '7.75 m'], ['2003', 'Universiade', 'Daegu, South Korea', '7th', '7.78 m']], 'name': 'csv/204-csv/706.tsv'}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikitq</td>\n",
       "      <td>0</td>\n",
       "      <td>[Year, Competition, Venue, Position, Notes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7613</th>\n",
       "      <td>How much Gain has a Long of 29, and an Avg/G smaller than 33.7?</td>\n",
       "      <td>{'header': ['Name', 'Gain', 'Loss', 'Long', 'Avg/G'], 'page_title': '2008 Kansas State Wildcats football team', 'page_id': '16404968', 'types': ['text', 'real', 'real', 'real', 'real'], 'id': '2-16404968-31', 'section_title': 'Rushing', 'caption': 'Rushing', 'rows': [['Lamark Brown', '458', '46', '28', '45.8'], ['Josh Freeman', '538', '134', '29', '33.7'], ['Logan Dold', '336', '3', '19', '33.3'], ['Total', '1,839', '249', '93', '132.5'], ['Opponents', '2,894', '282', '69', '217.7']], 'name': ''}</td>\n",
       "      <td>Aggregation</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>1</td>\n",
       "      <td>[Name, Gain, Loss, Long, Avg/G]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7614</th>\n",
       "      <td>What is the chapter for Illinois Wesleyan?</td>\n",
       "      <td>{'header': ['Chapter', 'Installation Date', 'Institution', 'Location', 'Inactive'], 'page_title': '', 'page_id': '', 'types': ['text', 'text', 'text', 'text', 'text'], 'id': '1-21821014-1', 'section_title': '', 'caption': '', 'rows': [['Gamma', 'Cannot handle non-empty timestamp argument! 1930', 'Oregon State University', 'Corvallis, Oregon', '1968'], ['Delta', 'Cannot handle non-empty timestamp argument! 1930', 'Whitman College', 'Walla Walla, Washington', '? (before 1950)'], ['Epsilon', '1931', 'University of New Mexico', 'Albuquerque, New Mexico', '? (evidence of activity in 1951)'], ['Iota', '1935', 'University of California, Berkeley', 'Berkeley, California', '? (evidence of activity in 1949)'], ['Lambda', 'Cannot handle non-empty timestamp argument! 1937', 'University of Arizona', 'Tucson, Arizona', '2000'], ['Nu', 'Cannot handle non-empty timestamp argument! 1939', 'University of California, Santa Barbara', 'Santa Barbara, California', '? (evidence of activity in 1972)'], ['Xi', '1941', 'Illinois Wesleyan', 'Bloomington, Illinois', '? (evidence of activity in 1945)'], ['Rho', 'Cannot handle non-empty timestamp argument! 1942', 'University of Southern California', 'Los Angeles', '? (evidence of activity in 1985)'], ['Sigma', 'Cannot handle non-empty timestamp argument! 1945', 'University of Texas, El Paso', 'El Paso, Texas', '? (evidence of activity in 1968 and 1974)']], 'name': 'table_21821014_1'}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>0</td>\n",
       "      <td>[Chapter, Installation Date, Institution, Location, Inactive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>What is the score when the tie is 9?</td>\n",
       "      <td>{'header': ['Tie no', 'Home team', 'Score', 'Away team', 'Date'], 'page_title': '1980–81 FA Cup', 'page_id': '17751859', 'types': ['text', 'text', 'text', 'text', 'text'], 'id': '2-17751859-4', 'section_title': 'Fourth Round Proper', 'caption': 'Fourth Round Proper', 'rows': [['1', 'Southampton', '3–1', 'Bristol Rovers', '24 January 1981'], ['2', 'Watford', '1–1', 'Wolverhampton Wanderers', '24 January 1981'], ['Replay', 'Wolverhampton Wanderers', '2–1', 'Watford', '27 January 1981'], ['3', 'Leicester City', '1–1', 'Exeter City', '24 January 1981'], ['Replay', 'Exeter City', '3–1', 'Leicester City', '28 January 1981'], ['4', 'Notts County', '0–1', 'Peterborough United', '24 January 1981'], ['5', 'Nottingham Forest', '1–0', 'Manchester United', '24 January 1981'], ['6', 'Middlesbrough', '1–0', 'West Bromwich Albion', '24 January 1981'], ['7', 'Everton', '2–1', 'Liverpool', '24 January 1981'], ['8', 'Shrewsbury Town', '0–0', 'Ipswich Town', '24 January 1981'], ['Replay', 'Ipswich Town', '3–0', 'Shrewsbury Town', '27 January 1981'], ['9', 'Wrexham', '2–1', 'Wimbledon', '24 January 1981'], ['10', 'Newcastle United', '2–1', 'Luton Town', '24 January 1981'], ['11', 'Tottenham Hotspur', '2–0', 'Hull City', '24 January 1981'], ['12', 'Manchester City', '6–0', 'Norwich City', '24 January 1981'], ['13', 'Fulham', '1–2', 'Charlton Athletic', '24 January 1981'], ['14', 'Barnsley', '1–1', 'Enfield', '24 January 1981'], ['Replay', 'Enfield', '0–3', 'Barnsley', '28 January 1981'], ['15', 'Coventry City', '3–2', 'Birmingham City', '24 January 1981'], ['16', 'Carlisle United', '1–1', 'Bristol City', '24 January 1981'], ['Replay', 'Bristol City', '5–0', 'Carlisle United', '28 January 1981']], 'name': ''}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>0</td>\n",
       "      <td>[Tie no, Home team, Score, Away team, Date]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7616</th>\n",
       "      <td>Name the D 47 when it has a D 45 of d 32</td>\n",
       "      <td>{'header': ['D 48', 'D 47', 'D 46', 'D 45', 'D 44', 'D 43', 'D 42', 'D 41'], 'page_title': 'United States Senate elections, 1958', 'page_id': '1178059', 'types': ['text', 'text', 'text', 'text', 'text', 'text', 'text', 'text'], 'id': '2-1178059-1', 'section_title': 'Senate composition before the elections', 'caption': 'Senate composition before the elections', 'rows': [['D 9', 'D 10', 'D 11', 'D 12', 'D 13', 'D 14', 'D 15', 'D 16'], ['D 28', 'D 27', 'D 26', 'D 25', 'D 24', 'D 23', 'D 22', 'D 21'], ['D 29', 'D 30', 'D 31', 'D 32', 'D 33', 'D 34', 'D 35', 'D 36'], ['D 48', 'D 47', 'D 46', 'D 45', 'D 44', 'D 43', 'D 42', 'D 41'], ['D 49', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority'], ['D 49', 'R 47', 'R 46', 'R 45', 'R 44', 'R 43', 'R 42', 'R 41'], ['R 29', 'R 30', 'R 31', 'R 32', 'R 33', 'R 34', 'R 35', 'R 36'], ['R 28', 'R 27', 'R 26', 'R 25', 'R 24', 'R 23', 'R 22', 'R 21'], ['R 9', 'R 10', 'R 11', 'R 12', 'R 13', 'R 14', 'R 15', 'R 16'], ['R 8', 'R 7', 'R 6', 'R 5', 'R 4', 'R 3', 'R 2', 'R 1']], 'name': ''}</td>\n",
       "      <td>Lookup</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>0</td>\n",
       "      <td>[D 48, D 47, D 46, D 45, D 44, D 43, D 42, D 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7617</th>\n",
       "      <td>What is the highest Loss, when Long is greater than 0, when Gain is greater than 484, and when Avg/g is greater than 126.4?</td>\n",
       "      <td>{'header': ['Name', 'Gain', 'Loss', 'Long', 'Avg/g'], 'page_title': '2008 East Carolina Pirates football team', 'page_id': '16768514', 'types': ['text', 'real', 'real', 'real', 'real'], 'id': '2-16768514-21', 'section_title': 'Rushing', 'caption': 'Rushing', 'rows': [['Whitley, Norman', '722', '24', '69', '49.9'], ['Simmons, Brandon', '484', '10', '28', '33.9'], ['Williams, Jonathan', '409', '29', '68', '54.3'], ['Rogers, J.R.', '150', '16', '25', '13.4'], ['Harris, Dwayne', '82', '6', '15', '7.6'], ['Pinkney, Patrick', '222', '172', '14', '3.6'], ['Bowman, Michael', '3', '0', '3', '0.6'], ['Gidrey, Kevin', '2', '0', '2', '0.1'], ['Simmons, Jason', '0', '0', '0', '0.0'], ['Ballard, Darnell', '0', '2', '0', '-2.0'], ['Kass, Rob', '36', '38', '20', '-0.3'], ['Sloan, Joe', '0', '6', '0', '-0.4'], ['Freeney, Darryl', '0', '10', '0', '-0.7'], ['Team', '0', '28', '0', '-4.7'], ['Total', '2110', '341', '69', '126.4']], 'name': ''}</td>\n",
       "      <td>Aggregation</td>\n",
       "      <td>wikisql</td>\n",
       "      <td>1</td>\n",
       "      <td>[Name, Gain, Loss, Long, Avg/g]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7618 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         question  \\\n",
       "0                                                                                           which team won previous to crettyard?   \n",
       "1                                 how many more passengers flew to los angeles than to saskatoon from manzanillo airport in 2013?   \n",
       "2                                                           after winning on four credits with a full house, what is your payout?   \n",
       "3                                                                           which players played the same position as ardo kreek?   \n",
       "4                                                                                        what was the venue when he placed first?   \n",
       "...                                                                                                                           ...   \n",
       "7613                                                              How much Gain has a Long of 29, and an Avg/G smaller than 33.7?   \n",
       "7614                                                                                  What is the chapter for Illinois Wesleyan?    \n",
       "7615                                                                                         What is the score when the tie is 9?   \n",
       "7616                                                                                     Name the D 47 when it has a D 45 of d 32   \n",
       "7617  What is the highest Loss, when Long is greater than 0, when Gain is greater than 484, and when Avg/g is greater than 126.4?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    table  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {'header': ['Team', 'County', 'Wins', 'Years won'], 'rows': [['Greystones', 'Wicklow', '1', '2011'], ['Ballymore Eustace', 'Kildare', '1', '2010'], ['Maynooth', 'Kildare', '1', '2009'], ['Ballyroan Abbey', 'Laois', '1', '2008'], ['Fingal Ravens', 'Dublin', '1', '2007'], ['Confey', 'Kildare', '1', '2006'], ['Crettyard', 'Laois', '1', '2005'], ['Wolfe Tones', 'Meath', '1', '2004'], ['Dundalk Gaels', 'Louth', '1', '2003']], 'name': 'csv/204-csv/772.tsv'}   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'header': ['Rank', 'City', 'Passengers', 'Ranking', 'Airline'], 'rows': [['1', 'United States, Los Angeles', '14,749', '', 'Alaska Airlines'], ['2', 'United States, Houston', '5,465', '', 'United Express'], ['3', 'Canada, Calgary', '3,761', '', 'Air Transat, WestJet'], ['4', 'Canada, Saskatoon', '2,282', '4', ''], ['5', 'Canada, Vancouver', '2,103', '', 'Air Transat'], ['6', 'United States, Phoenix', '1,829', '1', 'US Airways'], ['7', 'Canada, Toronto', '1,202', '1', 'Air Transat, CanJet'], ['8', 'Canada, Edmonton', '110', '', ''], ['9', 'United States, Oakland', '107', '', '']], 'name': 'csv/203-csv/515.tsv'}   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   {'header': ['Hand', '1 credit', '2 credits', '3 credits', '4 credits', '5 credits'], 'rows': [['Royal flush', '250', '500', '750', '1000', '4000*'], ['Straight flush', '60', '120', '180', '240', '400'], ['Four aces', '400', '800', '1200', '1600', '2000'], ['Four of a kind, 2-4', '100', '200', '300', '400', '500'], ['Four of a kind, 5-K', '50', '100', '150', '200', '250'], ['Full house', '8', '16', '24', '32', '40'], ['Flush', '5', '10', '15', '20', '25'], ['Straight', '4', '8', '12', '16', '20'], ['Three of a kind', '3', '6', '9', '12', '15'], ['Two pair', '1', '2', '3', '4', '5'], ['Jacks or better', '1', '2', '3', '4', '5'], ['Theoretical return', '98.68%', '98.68%', '98.68%', '98.68%', '99.92%*']], 'name': 'csv/203-csv/564.tsv'}   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              {'header': ['No.', 'Player', 'Birth Date', 'Weight', 'Height', 'Position', 'Current Club'], 'rows': [['4', 'Ardo Kreek', 'August 7, 1986 (age 27)', '96', '203', 'Middle blocker', 'Paris Volley'], ['5', 'Kert Toobal', 'June 3, 1979 (age 35)', '78', '189', 'Setter', 'Sivas 4 Eylül'], ['6', 'Martti Juhkami', 'June 6, 1988 (age 26)', '96', '196', 'Spiker', 'TV Bühl'], ['7', 'Argo Meresaar', 'January 13, 1980 (age 34)', '107', '206', 'Opposite', 'Bigbank Tartu'], ['8', 'Kusti Nõlvak', 'November 6, 1991 (age 22)', '81', '186', 'Setter', 'TTÜ VK'], ['9', 'Robert Täht', 'August 15, 1993 (age 20)', '80', '190', 'Spiker', 'Bigbank Tartu'], ['11', 'Oliver Venno', 'May 23, 1990 (age 24)', '105', '210', 'Opposite', 'Rennes Volley 35'], ['14', 'Rait Rikberg', 'August 30, 1982 (age 31)', '80', '174', 'Libero', 'Bigbank Tartu'], ['16', 'Edgar Järvekülg', 'June 12, 1988 (age 26)', '77', '186', 'Libero', 'Pärnu VK'], ['17', 'Siim Ennemuist', 'December 5, 1989 (age 24)', '89', '196', 'Middle blocker', 'TTÜ VK'], ['18', 'Jaanus Nõmmsalu', 'January 19, 1981 (age 33)', '94', '200', 'Spiker', 'TTÜ VK'], ['19', 'Andri Aganits', 'September 7, 1993 (age 20)', '99', '207', 'Middle Blocker', 'TV Bühl']], 'name': 'csv/203-csv/116.tsv'}   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               {'header': ['Year', 'Competition', 'Venue', 'Position', 'Notes'], 'rows': [['1996', 'World Junior Championships', 'Sydney, Australia', '15th (q)', '7.43 m'], ['1996', 'Asian Junior Championships', 'New Delhi, India', '1st', '7.68 m'], ['1999', 'World Championships', 'Seville, Spain', '6th', '8.01 m'], ['2001', 'East Asian Games', 'Osaka, Japan', '3rd', '7.77 m'], ['2002', 'Asian Championships', 'Colombo, Sri Lanka', '3rd', '7.91 m (w)'], ['2002', 'Asian Games', 'Busan, South Korea', '4th', '7.75 m'], ['2003', 'Universiade', 'Daegu, South Korea', '7th', '7.78 m']], 'name': 'csv/204-csv/706.tsv'}   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "7613                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                {'header': ['Name', 'Gain', 'Loss', 'Long', 'Avg/G'], 'page_title': '2008 Kansas State Wildcats football team', 'page_id': '16404968', 'types': ['text', 'real', 'real', 'real', 'real'], 'id': '2-16404968-31', 'section_title': 'Rushing', 'caption': 'Rushing', 'rows': [['Lamark Brown', '458', '46', '28', '45.8'], ['Josh Freeman', '538', '134', '29', '33.7'], ['Logan Dold', '336', '3', '19', '33.3'], ['Total', '1,839', '249', '93', '132.5'], ['Opponents', '2,894', '282', '69', '217.7']], 'name': ''}   \n",
       "7614                                                                                                                                                                                                                                                                                                  {'header': ['Chapter', 'Installation Date', 'Institution', 'Location', 'Inactive'], 'page_title': '', 'page_id': '', 'types': ['text', 'text', 'text', 'text', 'text'], 'id': '1-21821014-1', 'section_title': '', 'caption': '', 'rows': [['Gamma', 'Cannot handle non-empty timestamp argument! 1930', 'Oregon State University', 'Corvallis, Oregon', '1968'], ['Delta', 'Cannot handle non-empty timestamp argument! 1930', 'Whitman College', 'Walla Walla, Washington', '? (before 1950)'], ['Epsilon', '1931', 'University of New Mexico', 'Albuquerque, New Mexico', '? (evidence of activity in 1951)'], ['Iota', '1935', 'University of California, Berkeley', 'Berkeley, California', '? (evidence of activity in 1949)'], ['Lambda', 'Cannot handle non-empty timestamp argument! 1937', 'University of Arizona', 'Tucson, Arizona', '2000'], ['Nu', 'Cannot handle non-empty timestamp argument! 1939', 'University of California, Santa Barbara', 'Santa Barbara, California', '? (evidence of activity in 1972)'], ['Xi', '1941', 'Illinois Wesleyan', 'Bloomington, Illinois', '? (evidence of activity in 1945)'], ['Rho', 'Cannot handle non-empty timestamp argument! 1942', 'University of Southern California', 'Los Angeles', '? (evidence of activity in 1985)'], ['Sigma', 'Cannot handle non-empty timestamp argument! 1945', 'University of Texas, El Paso', 'El Paso, Texas', '? (evidence of activity in 1968 and 1974)']], 'name': 'table_21821014_1'}   \n",
       "7615  {'header': ['Tie no', 'Home team', 'Score', 'Away team', 'Date'], 'page_title': '1980–81 FA Cup', 'page_id': '17751859', 'types': ['text', 'text', 'text', 'text', 'text'], 'id': '2-17751859-4', 'section_title': 'Fourth Round Proper', 'caption': 'Fourth Round Proper', 'rows': [['1', 'Southampton', '3–1', 'Bristol Rovers', '24 January 1981'], ['2', 'Watford', '1–1', 'Wolverhampton Wanderers', '24 January 1981'], ['Replay', 'Wolverhampton Wanderers', '2–1', 'Watford', '27 January 1981'], ['3', 'Leicester City', '1–1', 'Exeter City', '24 January 1981'], ['Replay', 'Exeter City', '3–1', 'Leicester City', '28 January 1981'], ['4', 'Notts County', '0–1', 'Peterborough United', '24 January 1981'], ['5', 'Nottingham Forest', '1–0', 'Manchester United', '24 January 1981'], ['6', 'Middlesbrough', '1–0', 'West Bromwich Albion', '24 January 1981'], ['7', 'Everton', '2–1', 'Liverpool', '24 January 1981'], ['8', 'Shrewsbury Town', '0–0', 'Ipswich Town', '24 January 1981'], ['Replay', 'Ipswich Town', '3–0', 'Shrewsbury Town', '27 January 1981'], ['9', 'Wrexham', '2–1', 'Wimbledon', '24 January 1981'], ['10', 'Newcastle United', '2–1', 'Luton Town', '24 January 1981'], ['11', 'Tottenham Hotspur', '2–0', 'Hull City', '24 January 1981'], ['12', 'Manchester City', '6–0', 'Norwich City', '24 January 1981'], ['13', 'Fulham', '1–2', 'Charlton Athletic', '24 January 1981'], ['14', 'Barnsley', '1–1', 'Enfield', '24 January 1981'], ['Replay', 'Enfield', '0–3', 'Barnsley', '28 January 1981'], ['15', 'Coventry City', '3–2', 'Birmingham City', '24 January 1981'], ['16', 'Carlisle United', '1–1', 'Bristol City', '24 January 1981'], ['Replay', 'Bristol City', '5–0', 'Carlisle United', '28 January 1981']], 'name': ''}   \n",
       "7616                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 {'header': ['D 48', 'D 47', 'D 46', 'D 45', 'D 44', 'D 43', 'D 42', 'D 41'], 'page_title': 'United States Senate elections, 1958', 'page_id': '1178059', 'types': ['text', 'text', 'text', 'text', 'text', 'text', 'text', 'text'], 'id': '2-1178059-1', 'section_title': 'Senate composition before the elections', 'caption': 'Senate composition before the elections', 'rows': [['D 9', 'D 10', 'D 11', 'D 12', 'D 13', 'D 14', 'D 15', 'D 16'], ['D 28', 'D 27', 'D 26', 'D 25', 'D 24', 'D 23', 'D 22', 'D 21'], ['D 29', 'D 30', 'D 31', 'D 32', 'D 33', 'D 34', 'D 35', 'D 36'], ['D 48', 'D 47', 'D 46', 'D 45', 'D 44', 'D 43', 'D 42', 'D 41'], ['D 49', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority', '← Majority'], ['D 49', 'R 47', 'R 46', 'R 45', 'R 44', 'R 43', 'R 42', 'R 41'], ['R 29', 'R 30', 'R 31', 'R 32', 'R 33', 'R 34', 'R 35', 'R 36'], ['R 28', 'R 27', 'R 26', 'R 25', 'R 24', 'R 23', 'R 22', 'R 21'], ['R 9', 'R 10', 'R 11', 'R 12', 'R 13', 'R 14', 'R 15', 'R 16'], ['R 8', 'R 7', 'R 6', 'R 5', 'R 4', 'R 3', 'R 2', 'R 1']], 'name': ''}   \n",
       "7617                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            {'header': ['Name', 'Gain', 'Loss', 'Long', 'Avg/g'], 'page_title': '2008 East Carolina Pirates football team', 'page_id': '16768514', 'types': ['text', 'real', 'real', 'real', 'real'], 'id': '2-16768514-21', 'section_title': 'Rushing', 'caption': 'Rushing', 'rows': [['Whitley, Norman', '722', '24', '69', '49.9'], ['Simmons, Brandon', '484', '10', '28', '33.9'], ['Williams, Jonathan', '409', '29', '68', '54.3'], ['Rogers, J.R.', '150', '16', '25', '13.4'], ['Harris, Dwayne', '82', '6', '15', '7.6'], ['Pinkney, Patrick', '222', '172', '14', '3.6'], ['Bowman, Michael', '3', '0', '3', '0.6'], ['Gidrey, Kevin', '2', '0', '2', '0.1'], ['Simmons, Jason', '0', '0', '0', '0.0'], ['Ballard, Darnell', '0', '2', '0', '-2.0'], ['Kass, Rob', '36', '38', '20', '-0.3'], ['Sloan, Joe', '0', '6', '0', '-0.4'], ['Freeney, Darryl', '0', '10', '0', '-0.7'], ['Team', '0', '28', '0', '-4.7'], ['Total', '2110', '341', '69', '126.4']], 'name': ''}   \n",
       "\n",
       "       annotation   source  annotation_num  \\\n",
       "0          Lookup   wikitq               0   \n",
       "1     Aggregation   wikitq               1   \n",
       "2          Lookup   wikitq               0   \n",
       "3          Lookup   wikitq               0   \n",
       "4          Lookup   wikitq               0   \n",
       "...           ...      ...             ...   \n",
       "7613  Aggregation  wikisql               1   \n",
       "7614       Lookup  wikisql               0   \n",
       "7615       Lookup  wikisql               0   \n",
       "7616       Lookup  wikisql               0   \n",
       "7617  Aggregation  wikisql               1   \n",
       "\n",
       "                                                                 header  \n",
       "0                                       [Team, County, Wins, Years won]  \n",
       "1                            [Rank, City, Passengers, Ranking, Airline]  \n",
       "2          [Hand, 1 credit, 2 credits, 3 credits, 4 credits, 5 credits]  \n",
       "3     [No., Player, Birth Date, Weight, Height, Position, Current Club]  \n",
       "4                           [Year, Competition, Venue, Position, Notes]  \n",
       "...                                                                 ...  \n",
       "7613                                    [Name, Gain, Loss, Long, Avg/G]  \n",
       "7614      [Chapter, Installation Date, Institution, Location, Inactive]  \n",
       "7615                        [Tie no, Home team, Score, Away team, Date]  \n",
       "7616                   [D 48, D 47, D 46, D 45, D 44, D 43, D 42, D 41]  \n",
       "7617                                    [Name, Gain, Loss, Long, Avg/g]  \n",
       "\n",
       "[7618 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikiTQ, sql 데이터 섞기\n",
    "for split in ['train', 'validation']:\n",
    "    combined[split] = combined[split].sample(frac=1, random_state=7).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 분류기 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from easydict import EasyDict\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from easydict import EasyDict\n",
    "import gzip\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "import os\n",
    "from transformers import EarlyStoppingCallback\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from accelerate import Accelerator\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저를 쉽게 처리하기 위해 json 파일로 저장\n",
    "def convert_to_jsonl(df, out_path):\n",
    "    with gzip.open(out_path, 'wt', encoding='utf-8') as f:\n",
    "        for i in range(len(df)):\n",
    "\n",
    "            # header안에 리스트인 경우 문자로 변환해서 *로 합쳐줘야함 \n",
    "            header = df['header'][i]\n",
    "            if isinstance(header, list):\n",
    "                header = [str(h) for h in header]\n",
    "            else:\n",
    "                header = str(header)\n",
    "\n",
    "            # 라벨값이 numpy이면 json.dumps가 처리하지 못함\n",
    "            label = df['annotation_num'][i]\n",
    "            if isinstance(label, (np.integer, np.int64, np.int32)):\n",
    "                label = int(label)\n",
    "\n",
    "            item = {\n",
    "                'id': i,\n",
    "                'query': df['question'][i],\n",
    "                'header': ' * '.join(header),\n",
    "                'label': label,\n",
    "                'category' : df['annotation'][i]\n",
    "            }\n",
    "\n",
    "            f.write(json.dumps(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(example):\n",
    "#     return tokenizer(example['query'], example['header'], \n",
    "#                      #return_tensors='pt', \n",
    "#                      truncation=True, \n",
    "#                      padding='max_length', # 최대길이가 안되면 나머지 0으로 채움\n",
    "#                      max_length=128) # 문장 최대 길이\n",
    "\n",
    "def preprocess(example):\n",
    "    encoding = tokenizer(example['query'], example['header'], truncation=True)\n",
    "    encoding['labels'] = example['label']\n",
    "    return  encoding\n",
    "\n",
    "# def preprocess(example):\n",
    "#     encoding = tokenizer(example['query'], truncation=True)\n",
    "#     encoding['labels'] = example['label']\n",
    "#     return  encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"C:/Users/B6313/BERT-AGG-MODEL/wiki_cls_dataset/\"\n",
    "\n",
    "for split in ['train', 'validation']:\n",
    "    convert_to_jsonl(combined[split], os.path.join(output_path, f'{split}.jsonl.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 0, \"query\": \"in what year only did they compete in division 5\", \"header\": \"Year * Division * League * Regular Season * Playoffs * Open Cup\", \"label\": 0, \"category\": \"Lookup\"}\n",
      "\n",
      "{\"id\": 1, \"query\": \"What's the Finish rank of 31?\", \"header\": \"Year * Start * Qual * Rank * Finish * Laps\", \"label\": 0, \"category\": \"Lookup\"}\n",
      "\n",
      "{\"id\": 2, \"query\": \"Name the date successor seated for pennsylvania 17th\", \"header\": \"District * Vacator * Reason for change * Successor * Date successor seated\", \"label\": 0, \"category\": \"Lookup\"}\n",
      "\n",
      "{\"id\": 3, \"query\": \"What is the dates where Hillcrest Reserve is the home grounds?\", \"header\": \"Name * Nickname * First season * Location * Home ground(s) * Coach * Captain\", \"label\": 0, \"category\": \"Lookup\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = \"C:/Users/B6313/BERT-AGG-MODEL/wiki_cls_dataset/\"\n",
    "file_check = os.path.join(output_path + 'validation.jsonl.gz')\n",
    "with gzip.open(file_check, 'rt', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line)\n",
    "        if i > 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 44625 examples [00:00, 872200.86 examples/s]\n",
      "Generating validation split: 7618 examples [00:00, 708946.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files={\n",
    "    'train': os.path.join(output_path, 'train.jsonl.gz'),\n",
    "    'validation': os.path.join(output_path,'validation.jsonl.gz')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2789.0625"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((44625/8) * 10) * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'query': 'name someone else from scotland inducted before alan brazil.',\n",
       " 'header': 'Season * Level * Name * Position * Nationality * International\\\\ncaps',\n",
       " 'label': 0,\n",
       " 'category': 'Lookup'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 44625/44625 [00:01<00:00, 38451.59 examples/s]\n",
      "Map: 100%|██████████| 7618/7618 [00:00<00:00, 34908.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = 'google-bert/bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19], 'query': ['which country had the most cyclists finish within the top 10?', 'how many people were murdered in 1940/41?', 'how long did it take for the new york americans to win the national cup after 1936?', \"alfie's birthday party aired on january 19. what was the airdate of the next episode?\", 'what is the number of 1st place finishes across all events?', 'in which competition did hopley finish fist?', 'what is the total number of films with the language of kannada listed?', 'what was the number of people attending the toros mexico vs. monterrey flash game?', 'what time period had no shirt sponsor?', 'when was his first 1st place record?', 'does pat or john have the highest total?', 'what is the combined score of year end rankings before 2009?', 'how many more ships were wrecked in lake huron than in erie?', 'what was the total number of points scored by the tide in the last 3 games combined.', 'who came immediately after sebastian porto in the race?', \"what's the total number of festivals that occurred in october?\", 'what is the total number of skoda cars sold in the year 2005?', 'what was the number of times won on grass?', 'who won the most gold medals?', 'total wins by belgian riders'], 'header': ['Rank * Cyclist * Team * Time * UCI ProTour\\\\nPoints', 'Description Losses * 1939/40 * 1940/41 * 1941/42 * 1942/43 * 1943/44 * 1944/45 * Total', 'Year * Division * League * Reg. Season * Playoffs * National Cup', 'Series # * Season # * Title * Notes * Original air date', 'Date * Competition * Location * Country * Event * Placing * Rider * Nationality', 'Year * Competition * Venue * Position * Event * Notes', 'Year * Film * Role * Language * Notes', 'Game * Day * Date * Kickoff * Opponent * Results\\\\nScore * Results\\\\nRecord * Location * Attendance', 'Year * Kit Manufacturer * Shirt Sponsor * Back of Shirt Sponsor * Short Sponsor', 'Year * Competition * Venue * Position * Event * Notes', 'Name * League * FA Cup * League Cup * JP Trophy * Total', 'Tournament * 2004 * 2005 * 2006 * 2007 * 2008 * 2009 * 2010 * 2011 * 2012 * 2013 * 2014 * W–L', 'Ship * Type of Vessel * Lake * Location * Lives lost', 'Date * Opponent# * Rank# * Site * TV * Result * Attendance', 'Pos * Rider * Manufacturer * Time/Retired * Points', 'Date * Festival * Location * Awards * Link', 'Model * 1991 * 1995 * 1996 * 1997 * 1998 * 1999 * 2000 * 2001 * 2002 * 2003 * 2004 * 2005 * 2006 * 2007 * 2008 * 2009 * 2010 * 2011 * 2012 * 2013', 'Outcome * No. * Date * Championship * Surface * Opponent in the final * Score in the final', 'Rank * Nation * Gold * Silver * Bronze * Total', 'Place * Rider * Country * Team * Points * Wins'], 'label': [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1], 'category': ['Lookup', 'Aggregation', 'Aggregation', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Aggregation', 'Lookup', 'Aggregation', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Lookup', 'Aggregation'], 'input_ids': [[101, 2029, 2406, 2018, 1996, 2087, 21912, 3926, 2306, 1996, 2327, 2184, 1029, 102], [101, 2129, 2116, 2111, 2020, 7129, 1999, 3878, 1013, 4601, 1029, 102], [101, 2129, 2146, 2106, 2009, 2202, 2005, 1996, 2047, 2259, 4841, 2000, 2663, 1996, 2120, 2452, 2044, 4266, 1029, 102], [101, 24493, 2666, 1005, 1055, 5798, 2283, 4836, 2006, 2254, 2539, 1012, 2054, 2001, 1996, 2250, 13701, 1997, 1996, 2279, 2792, 1029, 102], [101, 2054, 2003, 1996, 2193, 1997, 3083, 2173, 12321, 2408, 2035, 2824, 1029, 102], [101, 1999, 2029, 2971, 2106, 6154, 3051, 3926, 7345, 1029, 102], [101, 2054, 2003, 1996, 2561, 2193, 1997, 3152, 2007, 1996, 2653, 1997, 13873, 3205, 1029, 102], [101, 2054, 2001, 1996, 2193, 1997, 2111, 7052, 1996, 23790, 2015, 3290, 5443, 1012, 26843, 5956, 2208, 1029, 102], [101, 2054, 2051, 2558, 2018, 2053, 3797, 10460, 1029, 102], [101, 2043, 2001, 2010, 2034, 3083, 2173, 2501, 1029, 102], [101, 2515, 6986, 2030, 2198, 2031, 1996, 3284, 2561, 1029, 102], [101, 2054, 2003, 1996, 4117, 3556, 1997, 2095, 2203, 10385, 2077, 2268, 1029, 102], [101, 2129, 2116, 2062, 3719, 2020, 18480, 1999, 2697, 21899, 2084, 1999, 13374, 1029, 102], [101, 2054, 2001, 1996, 2561, 2193, 1997, 2685, 3195, 2011, 1996, 10401, 1999, 1996, 2197, 1017, 2399, 4117, 1012, 102], [101, 2040, 2234, 3202, 2044, 6417, 13809, 1999, 1996, 2679, 1029, 102], [101, 2054, 1005, 1055, 1996, 2561, 2193, 1997, 7519, 2008, 4158, 1999, 2255, 1029, 102], [101, 2054, 2003, 1996, 2561, 2193, 1997, 15315, 13390, 3765, 2853, 1999, 1996, 2095, 2384, 1029, 102], [101, 2054, 2001, 1996, 2193, 1997, 2335, 2180, 2006, 5568, 1029, 102], [101, 2040, 2180, 1996, 2087, 2751, 6665, 1029, 102], [101, 2561, 5222, 2011, 6995, 8195, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]], 'labels': [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['test'][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Lookup\", \"Aggregation\"]\n",
    "Num_labels = len(labels)\n",
    "id2label = {id:label for id, label in enumerate(labels)}\n",
    "label2id = {label:id for id, label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Lookup', 1: 'Aggregation'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lookup': 0, 'Aggregation': 1}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path, num_labels=2, id2label=id2label, label2id=label2id\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1_score = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # eval_pred = (predictions, labels)\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # 다중분류\n",
    "    # 특정 i라벨의 확률 = 특정 i 라벨의 승산/모든 라벨의 승산 \n",
    "    # predictions = [batch_size, num_labels]\n",
    "    #probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
    "\n",
    "    #positive_class_probs = probabilities[:, 1] # 클래스 1일 확률 \n",
    "\n",
    "    # compute auc\n",
    "    #auc = np.round(auc_score.compute(prediction_scores=positive_class_probs,\n",
    "    #                reference=labels)['roc_auc'],3)\n",
    "\n",
    "    # 가장 로짓이 큰 라벨 추출\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, \n",
    "                                     references=labels)['accuracy'],3)\n",
    "    \n",
    "    f1 = np.round(f1_score.compute(predictions=predicted_classes, references=labels, average='macro')['f1'], 3) #  라벨별 f1-score를 산술평균한 것 : 현재 라벨의 갯수가 같아서 이렇게 써도 된다고 판단\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "lr = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='C:/Users/B6313/BERT-AGG-MODEL/bert-agg-NEW',\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=num_epochs,\n",
    "    warmup_steps=2800,                \n",
    "    weight_decay=0.01,\n",
    "    #logging_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=2800,\n",
    "    logging_dir=\"C:/Users/B6313/BERT-AGG-MODEL/logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to='none',\n",
    "    fp16=True,\n",
    "    #metric_for_best_model=\"f1\",\n",
    "    dataloader_num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\B6313\\AppData\\Local\\Temp\\ipykernel_6640\\4180147362.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='55790' max='55790' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [55790/55790 49:12, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.232396</td>\n",
       "      <td>0.931000</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.300576</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.907000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.353146</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.887000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306100</td>\n",
       "      <td>0.580951</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.552700</td>\n",
       "      <td>0.372341</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.681279</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.682711</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.681108</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.685200</td>\n",
       "      <td>0.681949</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.685100</td>\n",
       "      <td>0.681009</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.366000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=55790, training_loss=0.5202483972227046, metrics={'train_runtime': 2967.8325, 'train_samples_per_second': 150.362, 'train_steps_per_second': 18.798, 'total_flos': 1.240256849699574e+16, 'train_loss': 0.5202483972227046, 'epoch': 10.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(tokenized_dataset['test'])\n",
    "\n",
    "logits = preds.predictions\n",
    "labels = pred.label_ids\n",
    "\n",
    "metrics = compute_metrics((logits, labels))\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wiki_cls",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
